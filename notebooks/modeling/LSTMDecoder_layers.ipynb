{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Long Short Term Memory Decoder__\n",
    "\n",
    "### __Deep Learning__\n",
    "\n",
    "#### __Project: Image Captioning with Visual Attention__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.environ[\"PYTHONPATH\"])\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scripts.data_loading as dl\n",
    "import scripts.data_preprocessing as dp\n",
    "from scripts import model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "plt.rcParams[\"image.cmap\"] = \"plasma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.88s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train = dl.CocoCaptions(\n",
    "    dl.TRAINING_DATASET_PATHS[dl.DatasetType.TRAIN],\n",
    "    dp.VGGNET_PREPROCESSING_PIPELINE,\n",
    "    dp.TextPipeline(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_loader = dl.CocoLoader(coco_train, batch_size=2, num_workers=1)\n",
    "it = iter(coco_loader)\n",
    "image_batch, caption_batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.VGG19Encoder()\n",
    "feature_maps, feature_mean = encoder.forward(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = model.LSTMDecoder(\n",
    "    num_embeddings=len(coco_train.target_transform.vocabulary),\n",
    "    embedding_dim=8,\n",
    "    encoder_dim=feature_mean.shape[-1],\n",
    "    decoder_dim=16,\n",
    "    attention_dim=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = decoder.word_embedding(caption_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded caption shape = torch.Size([51])\n",
      "Embedding shape = torch.Size([51, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"One-hot encoded caption shape = {caption_batch[0].shape}\")\n",
    "print(f\"Embedding shape = {embeddings[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10000,    12,    78,    22,    34,   850,    31,     4,     0,   182,\n",
      "            1,  1421,    65,     2,     0,     8,   283,  1486,     0,    34,\n",
      "          204,     9,  1584,    47,    34,   924,     1,    34,  1118,     5,\n",
      "          133,   167,    62,    34,  1186,     4,   121,     4,    36,     2,\n",
      "          244,     6,    12,  1186,     1,   206,     6,   314, 10002,   139,\n",
      "        10001])\n",
      "tensor([[-1.6888,  0.1483,  0.9457, -1.1479,  0.1590,  0.7881,  1.7038, -1.1696],\n",
      "        [-1.2948, -1.5660,  1.2254, -0.6799, -1.4597, -0.3234, -0.8353,  1.5203],\n",
      "        [-0.9697, -0.9419, -0.6378,  0.6868,  0.4143,  0.0244,  1.5392, -0.6360],\n",
      "        [ 1.0276,  0.7994, -1.0511, -0.2812, -1.1780,  0.8434,  0.1806, -0.7388],\n",
      "        [ 0.9326, -0.7270,  0.3943,  1.3681,  0.6990, -0.9715, -0.6486,  0.0129],\n",
      "        [ 1.0822, -1.7418, -1.5915,  0.2949, -0.6686, -1.6818, -0.5635, -0.1142],\n",
      "        [-0.0780, -0.1424,  1.1705, -1.9569,  1.0202,  0.2618, -0.7559, -0.1468],\n",
      "        [-0.1433,  1.7406, -0.6169,  1.1675,  1.7930,  1.9487, -0.2920,  1.1258],\n",
      "        [-1.5542,  0.1927,  0.8941, -0.3123, -0.4306, -1.0928,  0.5560, -1.1622],\n",
      "        [-0.2716, -0.1412,  1.7125,  0.6561,  0.7499,  1.7425,  1.0060,  0.9497],\n",
      "        [-0.4020,  0.2905,  2.4924, -0.5300, -0.9347, -1.7835, -1.1590,  0.6428],\n",
      "        [-0.8639, -1.3399,  0.2081,  1.6337,  0.1949, -1.1044, -0.6511, -0.9261],\n",
      "        [ 1.4524, -0.5849, -0.1467, -0.1178, -1.2594, -2.5778, -0.4921,  1.4391],\n",
      "        [-0.3716,  0.3652,  0.4374, -1.0699, -0.3760,  0.3460,  0.1595, -0.4630],\n",
      "        [-1.5542,  0.1927,  0.8941, -0.3123, -0.4306, -1.0928,  0.5560, -1.1622],\n",
      "        [-1.9319,  1.0225,  0.1292, -1.7527,  1.1337,  2.6938,  2.3150, -0.2237],\n",
      "        [ 2.6162, -0.4843, -1.3923,  0.5916, -0.0852,  0.0716,  1.6827,  0.5356],\n",
      "        [-1.4256, -1.5398, -1.5617,  0.5740, -1.4453, -1.7248, -0.6488, -2.8406],\n",
      "        [-1.5542,  0.1927,  0.8941, -0.3123, -0.4306, -1.0928,  0.5560, -1.1622],\n",
      "        [ 0.9326, -0.7270,  0.3943,  1.3681,  0.6990, -0.9715, -0.6486,  0.0129],\n",
      "        [ 1.0829,  0.8988,  1.7373,  0.4409,  0.7986, -0.2277, -0.2366,  0.4234],\n",
      "        [-2.5892, -1.6591,  1.2482,  1.3330,  0.3066, -2.3020,  0.4214,  0.8191],\n",
      "        [ 0.0644, -0.1184,  1.3285, -0.0031,  0.7789,  1.8074,  1.4997,  1.0285],\n",
      "        [-0.1572,  1.1125,  0.1859,  1.5771, -0.8753, -0.0160, -1.8203,  0.5244],\n",
      "        [ 0.9326, -0.7270,  0.3943,  1.3681,  0.6990, -0.9715, -0.6486,  0.0129],\n",
      "        [ 0.3217,  1.5965, -0.1044,  1.4323,  0.8109, -0.7411,  0.3933,  0.6362],\n",
      "        [-0.4020,  0.2905,  2.4924, -0.5300, -0.9347, -1.7835, -1.1590,  0.6428],\n",
      "        [ 0.9326, -0.7270,  0.3943,  1.3681,  0.6990, -0.9715, -0.6486,  0.0129],\n",
      "        [ 1.2987,  0.0903, -0.4196, -0.3917,  0.7651,  1.0390, -0.3202, -0.9292],\n",
      "        [ 0.1949, -1.1438, -1.6203, -0.8864,  0.0844, -0.2284,  0.4526, -0.3784],\n",
      "        [-0.8327,  0.2218,  0.5535, -0.2850, -0.0779, -0.6547,  0.4108,  0.8405],\n",
      "        [-1.4299, -1.3702,  1.5124,  0.0402, -1.1065, -1.4028,  1.0445,  0.0234],\n",
      "        [-0.0958, -0.2428, -0.1928,  1.3727,  0.6339,  1.1258,  0.0499, -0.9533],\n",
      "        [ 0.9326, -0.7270,  0.3943,  1.3681,  0.6990, -0.9715, -0.6486,  0.0129],\n",
      "        [ 2.0515,  1.0144, -0.8161, -1.5781, -0.7433, -0.7022,  0.2737,  0.6982],\n",
      "        [-0.1433,  1.7406, -0.6169,  1.1675,  1.7930,  1.9487, -0.2920,  1.1258],\n",
      "        [ 0.0676, -1.4776, -1.7045,  0.6444, -1.1265,  0.9766, -0.6907, -0.0298],\n",
      "        [-0.1433,  1.7406, -0.6169,  1.1675,  1.7930,  1.9487, -0.2920,  1.1258],\n",
      "        [ 0.6861,  0.6845, -1.5617,  0.2954,  0.6390, -0.9233, -0.2062, -1.0530],\n",
      "        [-0.3716,  0.3652,  0.4374, -1.0699, -0.3760,  0.3460,  0.1595, -0.4630],\n",
      "        [-0.4327, -0.6887,  0.3657,  0.6348,  0.8052,  0.4365,  1.6253, -1.6418],\n",
      "        [-0.7259, -0.8064,  0.5536,  0.2376, -0.1327,  0.9686, -0.7599,  0.5105],\n",
      "        [-1.2948, -1.5660,  1.2254, -0.6799, -1.4597, -0.3234, -0.8353,  1.5203],\n",
      "        [ 2.0515,  1.0144, -0.8161, -1.5781, -0.7433, -0.7022,  0.2737,  0.6982],\n",
      "        [-0.4020,  0.2905,  2.4924, -0.5300, -0.9347, -1.7835, -1.1590,  0.6428],\n",
      "        [ 0.8834,  1.3642, -0.9823, -3.0517, -1.3914,  0.8414, -1.4817, -1.0524],\n",
      "        [-0.7259, -0.8064,  0.5536,  0.2376, -0.1327,  0.9686, -0.7599,  0.5105],\n",
      "        [ 1.5622,  0.1529,  0.0899,  0.5388,  0.3791, -0.4125, -1.2941,  0.0771],\n",
      "        [ 0.9334, -1.6668, -0.4562,  0.5775,  1.8090, -0.4805,  0.4617,  0.9044],\n",
      "        [ 1.4041, -1.3005,  0.2665, -1.3859, -0.2223,  0.2263, -0.0834,  0.1374],\n",
      "        [ 1.6991,  0.1847,  2.2600, -0.0078,  0.1373, -2.4367,  1.0577,  0.0748]],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(caption_batch[0])\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial h shape = torch.Size([2, 16])\n",
      "Initial c shape = torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "h = decoder.init_h(feature_mean)\n",
    "c = decoder.init_c(feature_mean)\n",
    "\n",
    "print(f\"Initial h shape = {h.shape}\")\n",
    "print(f\"Initial c shape = {c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1050, -0.1861, -0.0472,  0.0326, -0.0082, -0.0147,  0.3534, -0.0038,\n",
      "        -0.0790, -0.2035,  0.1511, -0.0622,  0.0550, -0.1406, -0.0302,  0.2211],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([-0.0905,  0.1944,  0.1244, -0.0852, -0.0559, -0.2246,  0.1145,  0.0561,\n",
      "        -0.1836, -0.2364,  0.0326,  0.1941,  0.0803,  0.0532,  0.0575, -0.1324],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Initial h, c of LSTM computed by MLP(feature_maps_mean)\n",
    "print(h[0])\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6991,  0.1847,  2.2600, -0.0078,  0.1373, -2.4367,  1.0577,  0.0748],\n",
       "        [ 1.6991,  0.1847,  2.2600, -0.0078,  0.1373, -2.4367,  1.0577,  0.0748]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get word embeddings of words at particular index of a caption in batch\n",
    "index = 50\n",
    "embeddings[:, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1412, 0.1195, 0.1757, 0.1956, 0.2014, 0.1619, 0.1296, 0.1212, 0.1625,\n",
       "         0.2444, 0.2788, 0.3305, 0.3097, 0.3634, 0.2017, 0.1454, 0.0949, 0.0646,\n",
       "         0.0738, 0.0580, 0.0685, 0.0834, 0.1497, 0.3198, 0.2564, 0.2706, 0.2274,\n",
       "         0.2668, 0.4305, 0.2778, 0.3106, 0.2719, 0.2167, 0.0923, 0.0908, 0.1187,\n",
       "         0.3236, 0.6264, 0.3948, 0.4090, 0.3418, 0.3622, 0.3230, 0.1912, 0.2707,\n",
       "         0.2215, 0.1806, 0.0852, 0.0931, 0.1090, 0.2908, 0.4428, 0.1921, 0.2183,\n",
       "         0.2172, 0.3397, 0.3572, 0.2309, 0.2297, 0.1774, 0.2011, 0.1361, 0.1507,\n",
       "         0.1538, 0.2483, 0.2350, 0.1305, 0.1665, 0.2978, 0.4957, 0.3393, 0.1802,\n",
       "         0.1848, 0.1314, 0.2549, 0.3474, 0.3141, 0.2434, 0.2089, 0.1747, 0.2000,\n",
       "         0.2210, 0.3853, 0.5794, 0.2008, 0.1367, 0.1783, 0.1296, 0.2880, 0.4784,\n",
       "         0.5109, 0.4420, 0.3456, 0.3144, 0.3219, 0.3269, 0.3614, 0.5044, 0.2522,\n",
       "         0.1661, 0.2265, 0.1435, 0.2713, 0.4259, 0.4878, 0.4517, 0.3450, 0.2899,\n",
       "         0.2741, 0.2950, 0.3401, 0.4399, 0.2932, 0.2313, 0.3534, 0.2611, 0.3260,\n",
       "         0.3536, 0.4130, 0.4175, 0.3646, 0.3397, 0.3101, 0.3242, 0.3097, 0.3636,\n",
       "         0.2150, 0.1634, 0.3246, 0.2434, 0.2508, 0.2482, 0.2858, 0.2830, 0.2809,\n",
       "         0.2907, 0.2592, 0.2438, 0.2179, 0.2397, 0.1872, 0.1783, 0.3992, 0.3072,\n",
       "         0.2603, 0.2323, 0.2626, 0.2672, 0.2824, 0.2967, 0.3095, 0.3110, 0.2057,\n",
       "         0.1938, 0.1669, 0.1667, 0.3848, 0.2800, 0.2690, 0.2479, 0.2765, 0.2835,\n",
       "         0.2868, 0.3166, 0.3409, 0.3610, 0.2152, 0.1754, 0.0764, 0.0413, 0.1209,\n",
       "         0.0874, 0.1069, 0.1267, 0.1686, 0.1794, 0.1630, 0.1515, 0.1526, 0.1545,\n",
       "         0.0859, 0.0868, 0.1290, 0.0643, 0.1268, 0.1148, 0.1455, 0.1668, 0.2439,\n",
       "         0.2470, 0.1805, 0.1701, 0.1976, 0.2303, 0.1296, 0.1079],\n",
       "        [0.1741, 0.0801, 0.1035, 0.1055, 0.1187, 0.1308, 0.1595, 0.1957, 0.2268,\n",
       "         0.2774, 0.3237, 0.4506, 0.3448, 0.3125, 0.0962, 0.0501, 0.0558, 0.0482,\n",
       "         0.0534, 0.0530, 0.0617, 0.0883, 0.1416, 0.2479, 0.3094, 0.3759, 0.2664,\n",
       "         0.2388, 0.1373, 0.0582, 0.0966, 0.0773, 0.0841, 0.0906, 0.1046, 0.1501,\n",
       "         0.2111, 0.4186, 0.4966, 0.5952, 0.4593, 0.3463, 0.1030, 0.0424, 0.0969,\n",
       "         0.0788, 0.0898, 0.1254, 0.1398, 0.1278, 0.1440, 0.2580, 0.2966, 0.2902,\n",
       "         0.1905, 0.1361, 0.0979, 0.0600, 0.1240, 0.1083, 0.1269, 0.2019, 0.3088,\n",
       "         0.3049, 0.1863, 0.2683, 0.2083, 0.1237, 0.0847, 0.0728, 0.0773, 0.0530,\n",
       "         0.1156, 0.1271, 0.1494, 0.3874, 0.7495, 0.7648, 0.3806, 0.1225, 0.0825,\n",
       "         0.0438, 0.0417, 0.0376, 0.0593, 0.0435, 0.0837, 0.1135, 0.1880, 0.5625,\n",
       "         0.9928, 1.0152, 0.6882, 0.1317, 0.0747, 0.0426, 0.0415, 0.0372, 0.0493,\n",
       "         0.0446, 0.0686, 0.0931, 0.2053, 0.6412, 1.1315, 1.0449, 0.7445, 0.1543,\n",
       "         0.0766, 0.0458, 0.0475, 0.0528, 0.0557, 0.0435, 0.0518, 0.0532, 0.1462,\n",
       "         0.3874, 0.6900, 0.5534, 0.3410, 0.1292, 0.0867, 0.0532, 0.0529, 0.0566,\n",
       "         0.0703, 0.0475, 0.0470, 0.0439, 0.0763, 0.1198, 0.1719, 0.1570, 0.1285,\n",
       "         0.0853, 0.0671, 0.0506, 0.0449, 0.0547, 0.0812, 0.0529, 0.0678, 0.0692,\n",
       "         0.0886, 0.1089, 0.1234, 0.1141, 0.0827, 0.0474, 0.0320, 0.0274, 0.0303,\n",
       "         0.0440, 0.1107, 0.0799, 0.0865, 0.0746, 0.0729, 0.0720, 0.0695, 0.0527,\n",
       "         0.0390, 0.0287, 0.0257, 0.0288, 0.0360, 0.0513, 0.0923, 0.0715, 0.0578,\n",
       "         0.0460, 0.0540, 0.0519, 0.0455, 0.0382, 0.0397, 0.0411, 0.0357, 0.0304,\n",
       "         0.0302, 0.0390, 0.1178, 0.0957, 0.0812, 0.0725, 0.0906, 0.0962, 0.0868,\n",
       "         0.0813, 0.0801, 0.0818, 0.0671, 0.0638, 0.0685, 0.0946]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6991,  0.1847,  2.2600, -0.0078,  0.1373, -2.4367,  1.0577,  0.0748,\n",
       "          0.1412,  0.1195,  0.1757,  0.1956,  0.2014,  0.1619,  0.1296,  0.1212,\n",
       "          0.1625,  0.2444,  0.2788,  0.3305,  0.3097,  0.3634,  0.2017,  0.1454,\n",
       "          0.0949,  0.0646,  0.0738,  0.0580,  0.0685,  0.0834,  0.1497,  0.3198,\n",
       "          0.2564,  0.2706,  0.2274,  0.2668,  0.4305,  0.2778,  0.3106,  0.2719,\n",
       "          0.2167,  0.0923,  0.0908,  0.1187,  0.3236,  0.6264,  0.3948,  0.4090,\n",
       "          0.3418,  0.3622,  0.3230,  0.1912,  0.2707,  0.2215,  0.1806,  0.0852,\n",
       "          0.0931,  0.1090,  0.2908,  0.4428,  0.1921,  0.2183,  0.2172,  0.3397,\n",
       "          0.3572,  0.2309,  0.2297,  0.1774,  0.2011,  0.1361,  0.1507,  0.1538,\n",
       "          0.2483,  0.2350,  0.1305,  0.1665,  0.2978,  0.4957,  0.3393,  0.1802,\n",
       "          0.1848,  0.1314,  0.2549,  0.3474,  0.3141,  0.2434,  0.2089,  0.1747,\n",
       "          0.2000,  0.2210,  0.3853,  0.5794,  0.2008,  0.1367,  0.1783,  0.1296,\n",
       "          0.2880,  0.4784,  0.5109,  0.4420,  0.3456,  0.3144,  0.3219,  0.3269,\n",
       "          0.3614,  0.5044,  0.2522,  0.1661,  0.2265,  0.1435,  0.2713,  0.4259,\n",
       "          0.4878,  0.4517,  0.3450,  0.2899,  0.2741,  0.2950,  0.3401,  0.4399,\n",
       "          0.2932,  0.2313,  0.3534,  0.2611,  0.3260,  0.3536,  0.4130,  0.4175,\n",
       "          0.3646,  0.3397,  0.3101,  0.3242,  0.3097,  0.3636,  0.2150,  0.1634,\n",
       "          0.3246,  0.2434,  0.2508,  0.2482,  0.2858,  0.2830,  0.2809,  0.2907,\n",
       "          0.2592,  0.2438,  0.2179,  0.2397,  0.1872,  0.1783,  0.3992,  0.3072,\n",
       "          0.2603,  0.2323,  0.2626,  0.2672,  0.2824,  0.2967,  0.3095,  0.3110,\n",
       "          0.2057,  0.1938,  0.1669,  0.1667,  0.3848,  0.2800,  0.2690,  0.2479,\n",
       "          0.2765,  0.2835,  0.2868,  0.3166,  0.3409,  0.3610,  0.2152,  0.1754,\n",
       "          0.0764,  0.0413,  0.1209,  0.0874,  0.1069,  0.1267,  0.1686,  0.1794,\n",
       "          0.1630,  0.1515,  0.1526,  0.1545,  0.0859,  0.0868,  0.1290,  0.0643,\n",
       "          0.1268,  0.1148,  0.1455,  0.1668,  0.2439,  0.2470,  0.1805,  0.1701,\n",
       "          0.1976,  0.2303,  0.1296,  0.1079],\n",
       "        [ 1.6991,  0.1847,  2.2600, -0.0078,  0.1373, -2.4367,  1.0577,  0.0748,\n",
       "          0.1741,  0.0801,  0.1035,  0.1055,  0.1187,  0.1308,  0.1595,  0.1957,\n",
       "          0.2268,  0.2774,  0.3237,  0.4506,  0.3448,  0.3125,  0.0962,  0.0501,\n",
       "          0.0558,  0.0482,  0.0534,  0.0530,  0.0617,  0.0883,  0.1416,  0.2479,\n",
       "          0.3094,  0.3759,  0.2664,  0.2388,  0.1373,  0.0582,  0.0966,  0.0773,\n",
       "          0.0841,  0.0906,  0.1046,  0.1501,  0.2111,  0.4186,  0.4966,  0.5952,\n",
       "          0.4593,  0.3463,  0.1030,  0.0424,  0.0969,  0.0788,  0.0898,  0.1254,\n",
       "          0.1398,  0.1278,  0.1440,  0.2580,  0.2966,  0.2902,  0.1905,  0.1361,\n",
       "          0.0979,  0.0600,  0.1240,  0.1083,  0.1269,  0.2019,  0.3088,  0.3049,\n",
       "          0.1863,  0.2683,  0.2083,  0.1237,  0.0847,  0.0728,  0.0773,  0.0530,\n",
       "          0.1156,  0.1271,  0.1494,  0.3874,  0.7495,  0.7648,  0.3806,  0.1225,\n",
       "          0.0825,  0.0438,  0.0417,  0.0376,  0.0593,  0.0435,  0.0837,  0.1135,\n",
       "          0.1880,  0.5625,  0.9928,  1.0152,  0.6882,  0.1317,  0.0747,  0.0426,\n",
       "          0.0415,  0.0372,  0.0493,  0.0446,  0.0686,  0.0931,  0.2053,  0.6412,\n",
       "          1.1315,  1.0449,  0.7445,  0.1543,  0.0766,  0.0458,  0.0475,  0.0528,\n",
       "          0.0557,  0.0435,  0.0518,  0.0532,  0.1462,  0.3874,  0.6900,  0.5534,\n",
       "          0.3410,  0.1292,  0.0867,  0.0532,  0.0529,  0.0566,  0.0703,  0.0475,\n",
       "          0.0470,  0.0439,  0.0763,  0.1198,  0.1719,  0.1570,  0.1285,  0.0853,\n",
       "          0.0671,  0.0506,  0.0449,  0.0547,  0.0812,  0.0529,  0.0678,  0.0692,\n",
       "          0.0886,  0.1089,  0.1234,  0.1141,  0.0827,  0.0474,  0.0320,  0.0274,\n",
       "          0.0303,  0.0440,  0.1107,  0.0799,  0.0865,  0.0746,  0.0729,  0.0720,\n",
       "          0.0695,  0.0527,  0.0390,  0.0287,  0.0257,  0.0288,  0.0360,  0.0513,\n",
       "          0.0923,  0.0715,  0.0578,  0.0460,  0.0540,  0.0519,  0.0455,  0.0382,\n",
       "          0.0397,  0.0411,  0.0357,  0.0304,  0.0302,  0.0390,  0.1178,  0.0957,\n",
       "          0.0812,  0.0725,  0.0906,  0.0962,  0.0868,  0.0813,  0.0801,  0.0818,\n",
       "          0.0671,  0.0638,  0.0685,  0.0946]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to concatenate context and embedding word\n",
    "torch.cat([embeddings[:, index], feature_mean], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, contexts = decoder.forward(feature_maps, feature_mean, caption_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 51])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of predicted words == caption_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2, 10004])\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10004])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2596e-04, 1.2361e-04, 1.1363e-04,  ..., 8.7298e-05, 9.3795e-05,\n",
       "        9.9695e-05], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 10_000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random guess prediction probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
