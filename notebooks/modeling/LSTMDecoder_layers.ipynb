{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Long Short Term Memory Decoder__\n",
    "\n",
    "### __Deep Learning__\n",
    "\n",
    "#### __Project: Image Captioning with Visual Attention__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.environ[\"PYTHONPATH\"])\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scripts.data_loading as dl\n",
    "import scripts.data_preprocessing as dp\n",
    "from scripts import model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "plt.rcParams[\"image.cmap\"] = \"plasma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.85s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train = dl.CocoCaptions(\n",
    "    dl.TRAINING_DATASET_PATHS[dl.DatasetType.TRAIN],\n",
    "    dp.VGGNET_PREPROCESSING_PIPELINE,\n",
    "    dp.TextPipeline(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_loader = dl.CocoLoader(coco_train, batch_size=2, num_workers=1)\n",
    "it = iter(coco_loader)\n",
    "image_batch, caption_batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.VGG19Encoder()\n",
    "feature_maps, feature_mean = encoder.forward(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = model.LSTMDecoder(\n",
    "    num_embeddings=len(coco_train.target_transform.vocabulary),\n",
    "    embedding_dim=8,\n",
    "    encoder_dim=feature_mean.shape[-1],\n",
    "    decoder_dim=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = decoder.word_embedding(caption_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded caption shape = torch.Size([51])\n",
      "Embedding shape = torch.Size([51, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"One-hot encoded caption shape = {caption_batch[0].shape}\")\n",
    "print(f\"Embedding shape = {embeddings[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10000,    12,    78,    22,    34,   850,    31,     4,     0,   182,\n",
      "            1,  1421,    65,     2,     0,     8,   283,  1486,     0,    34,\n",
      "          204,     9,  1584,    47,    34,   924,     1,    34,  1118,     5,\n",
      "          133,   167,    62,    34,  1186,     4,   121,     4,    36,     2,\n",
      "          244,     6,    12,  1186,     1,   206,     6,   314, 10002,   139,\n",
      "        10001])\n",
      "tensor([[-9.3962e-01,  9.3152e-02,  6.1815e-01, -2.0640e-01, -5.6856e-01,\n",
      "         -1.8623e+00, -3.1036e-01, -5.2126e-01],\n",
      "        [ 1.9570e-01, -6.1056e-01, -4.9649e-01, -5.5346e-01,  1.1907e+00,\n",
      "          6.5149e-01, -9.6779e-01, -1.5463e+00],\n",
      "        [-1.7656e+00,  1.4998e-01,  3.9044e-01, -1.0837e+00, -5.0703e-01,\n",
      "          1.0221e+00,  3.2809e-01, -7.4305e-01],\n",
      "        [ 1.0314e+00,  1.3068e+00,  2.3626e+00, -1.4334e+00,  1.3630e-01,\n",
      "         -2.1674e-01,  1.3389e+00, -1.0174e+00],\n",
      "        [ 1.1968e+00, -1.4517e+00, -4.5591e-01, -3.6691e-01, -2.0578e-01,\n",
      "          1.9423e+00,  1.2538e-01, -6.6268e-01],\n",
      "        [-1.0163e+00, -5.5978e-01, -1.1808e+00,  6.0138e-01,  1.8517e+00,\n",
      "          1.9230e+00,  6.2574e-01, -4.3177e-01],\n",
      "        [-1.0540e+00,  2.8061e-01, -1.1112e+00, -1.5289e+00, -4.9420e-01,\n",
      "         -9.7603e-01,  1.4763e+00, -7.1580e-01],\n",
      "        [-1.2098e+00,  1.5825e+00,  1.7316e+00, -1.1414e+00, -8.2984e-01,\n",
      "         -1.8018e+00, -1.5531e+00, -2.2089e+00],\n",
      "        [-8.9738e-01, -4.7139e-01,  4.1578e-01,  2.1495e+00,  3.5232e-01,\n",
      "         -5.4655e-01,  7.7200e-01,  4.6564e-01],\n",
      "        [ 1.2346e-01,  1.6318e+00, -2.7717e+00, -7.0674e-02,  3.5402e-01,\n",
      "          5.4172e-01, -2.6378e+00,  3.7039e-01],\n",
      "        [ 4.4102e-01,  7.0213e-01, -1.4563e-01,  7.3802e-01, -2.9699e-01,\n",
      "         -8.9023e-02,  2.7844e-01,  5.1102e-01],\n",
      "        [ 8.3579e-03, -8.5219e-02,  1.2336e+00, -1.1338e+00, -1.3219e+00,\n",
      "         -3.9853e-01, -1.2665e+00,  1.2256e+00],\n",
      "        [-4.1207e-01, -1.8502e+00,  2.1996e+00,  2.5251e-01,  1.2159e+00,\n",
      "         -7.9386e-02, -3.9440e-01,  2.1270e+00],\n",
      "        [ 1.3486e+00, -2.0110e+00,  2.0151e+00,  8.4007e-04,  2.0154e-01,\n",
      "          2.5938e-01, -6.5888e-01,  7.9276e-01],\n",
      "        [-8.9738e-01, -4.7139e-01,  4.1578e-01,  2.1495e+00,  3.5232e-01,\n",
      "         -5.4655e-01,  7.7200e-01,  4.6564e-01],\n",
      "        [-1.6690e-01, -8.5948e-01,  1.7171e-01,  1.5086e+00,  5.4673e-01,\n",
      "         -1.9293e-01,  8.5740e-01, -7.1855e-02],\n",
      "        [ 1.3791e+00, -1.0832e+00, -7.8177e-01,  6.5674e-01,  1.1008e+00,\n",
      "          1.0240e+00,  1.2399e+00, -2.9993e-01],\n",
      "        [ 1.3419e+00, -2.0186e-01,  5.6646e-01, -5.1399e-01, -4.6195e-01,\n",
      "         -1.3428e+00, -2.6206e-01, -7.2939e-01],\n",
      "        [-8.9738e-01, -4.7139e-01,  4.1578e-01,  2.1495e+00,  3.5232e-01,\n",
      "         -5.4655e-01,  7.7200e-01,  4.6564e-01],\n",
      "        [ 1.1968e+00, -1.4517e+00, -4.5591e-01, -3.6691e-01, -2.0578e-01,\n",
      "          1.9423e+00,  1.2538e-01, -6.6268e-01],\n",
      "        [-5.7598e-01, -1.7343e-01,  6.3315e-02, -1.2591e-01, -8.6006e-01,\n",
      "          1.3048e+00,  1.1182e+00, -1.4315e+00],\n",
      "        [ 1.0087e+00,  9.1851e-01,  1.1098e+00,  1.6659e-01, -5.0197e-01,\n",
      "         -7.5890e-02, -7.8536e-01,  7.4752e-02],\n",
      "        [ 7.2534e-01,  1.1391e+00, -8.2840e-01, -1.5987e-01, -2.3256e-01,\n",
      "         -1.6888e+00, -3.5016e-01,  7.5900e-01],\n",
      "        [-3.2745e-01, -5.9919e-01,  1.0373e+00, -1.1538e+00,  2.3803e+00,\n",
      "         -1.6241e+00,  1.6730e-01, -4.6213e-01],\n",
      "        [ 1.1968e+00, -1.4517e+00, -4.5591e-01, -3.6691e-01, -2.0578e-01,\n",
      "          1.9423e+00,  1.2538e-01, -6.6268e-01],\n",
      "        [-7.6387e-01, -4.7514e-01, -6.7366e-01,  1.2630e+00,  1.4078e-01,\n",
      "          9.8579e-01, -3.0443e-01, -1.9858e-01],\n",
      "        [ 4.4102e-01,  7.0213e-01, -1.4563e-01,  7.3802e-01, -2.9699e-01,\n",
      "         -8.9023e-02,  2.7844e-01,  5.1102e-01],\n",
      "        [ 1.1968e+00, -1.4517e+00, -4.5591e-01, -3.6691e-01, -2.0578e-01,\n",
      "          1.9423e+00,  1.2538e-01, -6.6268e-01],\n",
      "        [-8.6900e-01, -6.6112e-01, -1.1122e+00, -9.1190e-01,  5.8357e-01,\n",
      "         -1.8589e+00,  1.2664e-01, -7.4370e-01],\n",
      "        [ 3.4293e-01,  1.1467e+00,  1.8934e-02, -1.3560e+00, -1.2226e-01,\n",
      "         -1.9752e+00, -5.6664e-01, -6.4590e-01],\n",
      "        [ 7.0174e-01,  2.4902e-01, -6.7625e-01, -1.6088e+00,  1.6102e-01,\n",
      "          1.0673e+00, -1.0958e+00, -1.5469e-01],\n",
      "        [ 2.4765e-01, -1.1854e-01,  1.3912e+00,  6.0852e-01,  5.1331e-01,\n",
      "          5.8352e-01,  9.1657e-02,  9.4664e-01],\n",
      "        [ 3.1324e-01, -1.4308e-01,  7.2211e-02, -2.2217e-01,  1.0012e+00,\n",
      "          1.5054e+00, -6.3732e-01,  2.2489e+00],\n",
      "        [ 1.1968e+00, -1.4517e+00, -4.5591e-01, -3.6691e-01, -2.0578e-01,\n",
      "          1.9423e+00,  1.2538e-01, -6.6268e-01],\n",
      "        [ 1.3467e+00,  5.2574e-02,  1.7670e+00,  5.4264e-01, -1.2151e+00,\n",
      "         -4.5140e-02,  8.6719e-01,  2.3347e+00],\n",
      "        [-1.2098e+00,  1.5825e+00,  1.7316e+00, -1.1414e+00, -8.2984e-01,\n",
      "         -1.8018e+00, -1.5531e+00, -2.2089e+00],\n",
      "        [ 2.4419e+00, -3.1904e-01, -7.9757e-01, -8.7858e-01, -3.0123e-01,\n",
      "          1.4836e-01, -1.7646e-02,  7.2647e-01],\n",
      "        [-1.2098e+00,  1.5825e+00,  1.7316e+00, -1.1414e+00, -8.2984e-01,\n",
      "         -1.8018e+00, -1.5531e+00, -2.2089e+00],\n",
      "        [-1.1719e-01, -2.9076e-02,  1.3098e-01, -2.6823e-01,  4.0677e-01,\n",
      "          1.6489e+00,  1.7779e+00,  5.4702e-01],\n",
      "        [ 1.3486e+00, -2.0110e+00,  2.0151e+00,  8.4007e-04,  2.0154e-01,\n",
      "          2.5938e-01, -6.5888e-01,  7.9276e-01],\n",
      "        [ 7.9167e-01,  1.9008e-01, -6.4828e-01, -1.2347e+00,  1.6144e+00,\n",
      "         -3.0507e-01,  5.4685e-01, -4.3685e-01],\n",
      "        [ 7.3314e-02, -2.8030e-01,  1.0582e+00,  1.5978e+00,  1.5361e-01,\n",
      "          5.6716e-01,  8.4226e-01, -1.5397e-02],\n",
      "        [ 1.9570e-01, -6.1056e-01, -4.9649e-01, -5.5346e-01,  1.1907e+00,\n",
      "          6.5149e-01, -9.6779e-01, -1.5463e+00],\n",
      "        [ 1.3467e+00,  5.2574e-02,  1.7670e+00,  5.4264e-01, -1.2151e+00,\n",
      "         -4.5140e-02,  8.6719e-01,  2.3347e+00],\n",
      "        [ 4.4102e-01,  7.0213e-01, -1.4563e-01,  7.3802e-01, -2.9699e-01,\n",
      "         -8.9023e-02,  2.7844e-01,  5.1102e-01],\n",
      "        [-3.8804e-01,  1.2793e+00, -1.1669e+00,  3.3642e-02, -8.1754e-01,\n",
      "          9.8720e-01, -7.0434e-01, -1.1706e+00],\n",
      "        [ 7.3314e-02, -2.8030e-01,  1.0582e+00,  1.5978e+00,  1.5361e-01,\n",
      "          5.6716e-01,  8.4226e-01, -1.5397e-02],\n",
      "        [ 7.5956e-01, -1.0316e+00,  4.7531e-01, -2.0387e-01,  1.0123e-01,\n",
      "          9.4141e-01,  2.4570e-01, -3.6643e-01],\n",
      "        [-1.0450e+00, -2.9131e+00, -1.0441e+00, -5.4518e-01, -2.9162e+00,\n",
      "          1.0159e+00,  3.7209e-03, -2.9290e-01],\n",
      "        [ 9.8650e-02,  4.0579e-01, -7.0830e-01,  2.1108e-01,  2.9165e-01,\n",
      "         -4.1181e-01, -2.7320e-01,  2.5805e-01],\n",
      "        [ 4.9803e-01, -2.3161e-01, -6.5233e-01, -1.3926e-01,  9.4346e-01,\n",
      "          1.4716e+00, -8.1706e-01, -6.8672e-01]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(caption_batch[0])\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial h shape = torch.Size([2, 16])\n",
      "Initial c shape = torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "h = decoder.init_h(feature_mean)\n",
    "c = decoder.init_c(feature_mean)\n",
    "\n",
    "print(f\"Initial h shape = {h.shape}\")\n",
    "print(f\"Initial c shape = {c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1606, -0.3352, -0.0846,  0.0099, -0.0954, -0.0201, -0.0240, -0.1515,\n",
      "         0.0893,  0.1505,  0.3814, -0.0017, -0.0455, -0.1599, -0.0944, -0.1832],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([-0.1540,  0.0020, -0.2214,  0.0251, -0.0699,  0.1348,  0.0101,  0.0607,\n",
      "        -0.2220,  0.1356,  0.1051,  0.2651,  0.0599, -0.2680,  0.0507, -0.2102],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Initial h, c of LSTM computed by MLP(feature_maps_mean)\n",
    "print(h[0])\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4980, -0.2316, -0.6523, -0.1393,  0.9435,  1.4716, -0.8171, -0.6867],\n",
       "        [ 0.4980, -0.2316, -0.6523, -0.1393,  0.9435,  1.4716, -0.8171, -0.6867]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get word embeddings of words at particular index of a caption in batch\n",
    "index = 50\n",
    "embeddings[:, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1412, 0.1195, 0.1757, 0.1956, 0.2014, 0.1619, 0.1296, 0.1212, 0.1625,\n",
       "         0.2444, 0.2788, 0.3305, 0.3097, 0.3634, 0.2017, 0.1454, 0.0949, 0.0646,\n",
       "         0.0738, 0.0580, 0.0685, 0.0834, 0.1497, 0.3198, 0.2564, 0.2706, 0.2274,\n",
       "         0.2668, 0.4305, 0.2778, 0.3106, 0.2719, 0.2167, 0.0923, 0.0908, 0.1187,\n",
       "         0.3236, 0.6264, 0.3948, 0.4090, 0.3418, 0.3622, 0.3230, 0.1912, 0.2707,\n",
       "         0.2215, 0.1806, 0.0852, 0.0931, 0.1090, 0.2908, 0.4428, 0.1921, 0.2183,\n",
       "         0.2172, 0.3397, 0.3572, 0.2309, 0.2297, 0.1774, 0.2011, 0.1361, 0.1507,\n",
       "         0.1538, 0.2483, 0.2350, 0.1305, 0.1665, 0.2978, 0.4957, 0.3393, 0.1802,\n",
       "         0.1848, 0.1314, 0.2549, 0.3474, 0.3141, 0.2434, 0.2089, 0.1747, 0.2000,\n",
       "         0.2210, 0.3853, 0.5794, 0.2008, 0.1367, 0.1783, 0.1296, 0.2880, 0.4784,\n",
       "         0.5109, 0.4420, 0.3456, 0.3144, 0.3219, 0.3269, 0.3614, 0.5044, 0.2522,\n",
       "         0.1661, 0.2265, 0.1435, 0.2713, 0.4259, 0.4878, 0.4517, 0.3450, 0.2899,\n",
       "         0.2741, 0.2950, 0.3401, 0.4399, 0.2932, 0.2313, 0.3534, 0.2611, 0.3260,\n",
       "         0.3536, 0.4130, 0.4175, 0.3646, 0.3397, 0.3101, 0.3242, 0.3097, 0.3636,\n",
       "         0.2150, 0.1634, 0.3246, 0.2434, 0.2508, 0.2482, 0.2858, 0.2830, 0.2809,\n",
       "         0.2907, 0.2592, 0.2438, 0.2179, 0.2397, 0.1872, 0.1783, 0.3992, 0.3072,\n",
       "         0.2603, 0.2323, 0.2626, 0.2672, 0.2824, 0.2967, 0.3095, 0.3110, 0.2057,\n",
       "         0.1938, 0.1669, 0.1667, 0.3848, 0.2800, 0.2690, 0.2479, 0.2765, 0.2835,\n",
       "         0.2868, 0.3166, 0.3409, 0.3610, 0.2152, 0.1754, 0.0764, 0.0413, 0.1209,\n",
       "         0.0874, 0.1069, 0.1267, 0.1686, 0.1794, 0.1630, 0.1515, 0.1526, 0.1545,\n",
       "         0.0859, 0.0868, 0.1290, 0.0643, 0.1268, 0.1148, 0.1455, 0.1668, 0.2439,\n",
       "         0.2470, 0.1805, 0.1701, 0.1976, 0.2303, 0.1296, 0.1079],\n",
       "        [0.1741, 0.0801, 0.1035, 0.1055, 0.1187, 0.1308, 0.1595, 0.1957, 0.2268,\n",
       "         0.2774, 0.3237, 0.4506, 0.3448, 0.3125, 0.0962, 0.0501, 0.0558, 0.0482,\n",
       "         0.0534, 0.0530, 0.0617, 0.0883, 0.1416, 0.2479, 0.3094, 0.3759, 0.2664,\n",
       "         0.2388, 0.1373, 0.0582, 0.0966, 0.0773, 0.0841, 0.0906, 0.1046, 0.1501,\n",
       "         0.2111, 0.4186, 0.4966, 0.5952, 0.4593, 0.3463, 0.1030, 0.0424, 0.0969,\n",
       "         0.0788, 0.0898, 0.1254, 0.1398, 0.1278, 0.1440, 0.2580, 0.2966, 0.2902,\n",
       "         0.1905, 0.1361, 0.0979, 0.0600, 0.1240, 0.1083, 0.1269, 0.2019, 0.3088,\n",
       "         0.3049, 0.1863, 0.2683, 0.2083, 0.1237, 0.0847, 0.0728, 0.0773, 0.0530,\n",
       "         0.1156, 0.1271, 0.1494, 0.3874, 0.7495, 0.7648, 0.3806, 0.1225, 0.0825,\n",
       "         0.0438, 0.0417, 0.0376, 0.0593, 0.0435, 0.0837, 0.1135, 0.1880, 0.5625,\n",
       "         0.9928, 1.0152, 0.6882, 0.1317, 0.0747, 0.0426, 0.0415, 0.0372, 0.0493,\n",
       "         0.0446, 0.0686, 0.0931, 0.2053, 0.6412, 1.1315, 1.0449, 0.7445, 0.1543,\n",
       "         0.0766, 0.0458, 0.0475, 0.0528, 0.0557, 0.0435, 0.0518, 0.0532, 0.1462,\n",
       "         0.3874, 0.6900, 0.5534, 0.3410, 0.1292, 0.0867, 0.0532, 0.0529, 0.0566,\n",
       "         0.0703, 0.0475, 0.0470, 0.0439, 0.0763, 0.1198, 0.1719, 0.1570, 0.1285,\n",
       "         0.0853, 0.0671, 0.0506, 0.0449, 0.0547, 0.0812, 0.0529, 0.0678, 0.0692,\n",
       "         0.0886, 0.1089, 0.1234, 0.1141, 0.0827, 0.0474, 0.0320, 0.0274, 0.0303,\n",
       "         0.0440, 0.1107, 0.0799, 0.0865, 0.0746, 0.0729, 0.0720, 0.0695, 0.0527,\n",
       "         0.0390, 0.0287, 0.0257, 0.0288, 0.0360, 0.0513, 0.0923, 0.0715, 0.0578,\n",
       "         0.0460, 0.0540, 0.0519, 0.0455, 0.0382, 0.0397, 0.0411, 0.0357, 0.0304,\n",
       "         0.0302, 0.0390, 0.1178, 0.0957, 0.0812, 0.0725, 0.0906, 0.0962, 0.0868,\n",
       "         0.0813, 0.0801, 0.0818, 0.0671, 0.0638, 0.0685, 0.0946]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4980, -0.2316, -0.6523, -0.1393,  0.9435,  1.4716, -0.8171, -0.6867,\n",
       "          0.1412,  0.1195,  0.1757,  0.1956,  0.2014,  0.1619,  0.1296,  0.1212,\n",
       "          0.1625,  0.2444,  0.2788,  0.3305,  0.3097,  0.3634,  0.2017,  0.1454,\n",
       "          0.0949,  0.0646,  0.0738,  0.0580,  0.0685,  0.0834,  0.1497,  0.3198,\n",
       "          0.2564,  0.2706,  0.2274,  0.2668,  0.4305,  0.2778,  0.3106,  0.2719,\n",
       "          0.2167,  0.0923,  0.0908,  0.1187,  0.3236,  0.6264,  0.3948,  0.4090,\n",
       "          0.3418,  0.3622,  0.3230,  0.1912,  0.2707,  0.2215,  0.1806,  0.0852,\n",
       "          0.0931,  0.1090,  0.2908,  0.4428,  0.1921,  0.2183,  0.2172,  0.3397,\n",
       "          0.3572,  0.2309,  0.2297,  0.1774,  0.2011,  0.1361,  0.1507,  0.1538,\n",
       "          0.2483,  0.2350,  0.1305,  0.1665,  0.2978,  0.4957,  0.3393,  0.1802,\n",
       "          0.1848,  0.1314,  0.2549,  0.3474,  0.3141,  0.2434,  0.2089,  0.1747,\n",
       "          0.2000,  0.2210,  0.3853,  0.5794,  0.2008,  0.1367,  0.1783,  0.1296,\n",
       "          0.2880,  0.4784,  0.5109,  0.4420,  0.3456,  0.3144,  0.3219,  0.3269,\n",
       "          0.3614,  0.5044,  0.2522,  0.1661,  0.2265,  0.1435,  0.2713,  0.4259,\n",
       "          0.4878,  0.4517,  0.3450,  0.2899,  0.2741,  0.2950,  0.3401,  0.4399,\n",
       "          0.2932,  0.2313,  0.3534,  0.2611,  0.3260,  0.3536,  0.4130,  0.4175,\n",
       "          0.3646,  0.3397,  0.3101,  0.3242,  0.3097,  0.3636,  0.2150,  0.1634,\n",
       "          0.3246,  0.2434,  0.2508,  0.2482,  0.2858,  0.2830,  0.2809,  0.2907,\n",
       "          0.2592,  0.2438,  0.2179,  0.2397,  0.1872,  0.1783,  0.3992,  0.3072,\n",
       "          0.2603,  0.2323,  0.2626,  0.2672,  0.2824,  0.2967,  0.3095,  0.3110,\n",
       "          0.2057,  0.1938,  0.1669,  0.1667,  0.3848,  0.2800,  0.2690,  0.2479,\n",
       "          0.2765,  0.2835,  0.2868,  0.3166,  0.3409,  0.3610,  0.2152,  0.1754,\n",
       "          0.0764,  0.0413,  0.1209,  0.0874,  0.1069,  0.1267,  0.1686,  0.1794,\n",
       "          0.1630,  0.1515,  0.1526,  0.1545,  0.0859,  0.0868,  0.1290,  0.0643,\n",
       "          0.1268,  0.1148,  0.1455,  0.1668,  0.2439,  0.2470,  0.1805,  0.1701,\n",
       "          0.1976,  0.2303,  0.1296,  0.1079],\n",
       "        [ 0.4980, -0.2316, -0.6523, -0.1393,  0.9435,  1.4716, -0.8171, -0.6867,\n",
       "          0.1741,  0.0801,  0.1035,  0.1055,  0.1187,  0.1308,  0.1595,  0.1957,\n",
       "          0.2268,  0.2774,  0.3237,  0.4506,  0.3448,  0.3125,  0.0962,  0.0501,\n",
       "          0.0558,  0.0482,  0.0534,  0.0530,  0.0617,  0.0883,  0.1416,  0.2479,\n",
       "          0.3094,  0.3759,  0.2664,  0.2388,  0.1373,  0.0582,  0.0966,  0.0773,\n",
       "          0.0841,  0.0906,  0.1046,  0.1501,  0.2111,  0.4186,  0.4966,  0.5952,\n",
       "          0.4593,  0.3463,  0.1030,  0.0424,  0.0969,  0.0788,  0.0898,  0.1254,\n",
       "          0.1398,  0.1278,  0.1440,  0.2580,  0.2966,  0.2902,  0.1905,  0.1361,\n",
       "          0.0979,  0.0600,  0.1240,  0.1083,  0.1269,  0.2019,  0.3088,  0.3049,\n",
       "          0.1863,  0.2683,  0.2083,  0.1237,  0.0847,  0.0728,  0.0773,  0.0530,\n",
       "          0.1156,  0.1271,  0.1494,  0.3874,  0.7495,  0.7648,  0.3806,  0.1225,\n",
       "          0.0825,  0.0438,  0.0417,  0.0376,  0.0593,  0.0435,  0.0837,  0.1135,\n",
       "          0.1880,  0.5625,  0.9928,  1.0152,  0.6882,  0.1317,  0.0747,  0.0426,\n",
       "          0.0415,  0.0372,  0.0493,  0.0446,  0.0686,  0.0931,  0.2053,  0.6412,\n",
       "          1.1315,  1.0449,  0.7445,  0.1543,  0.0766,  0.0458,  0.0475,  0.0528,\n",
       "          0.0557,  0.0435,  0.0518,  0.0532,  0.1462,  0.3874,  0.6900,  0.5534,\n",
       "          0.3410,  0.1292,  0.0867,  0.0532,  0.0529,  0.0566,  0.0703,  0.0475,\n",
       "          0.0470,  0.0439,  0.0763,  0.1198,  0.1719,  0.1570,  0.1285,  0.0853,\n",
       "          0.0671,  0.0506,  0.0449,  0.0547,  0.0812,  0.0529,  0.0678,  0.0692,\n",
       "          0.0886,  0.1089,  0.1234,  0.1141,  0.0827,  0.0474,  0.0320,  0.0274,\n",
       "          0.0303,  0.0440,  0.1107,  0.0799,  0.0865,  0.0746,  0.0729,  0.0720,\n",
       "          0.0695,  0.0527,  0.0390,  0.0287,  0.0257,  0.0288,  0.0360,  0.0513,\n",
       "          0.0923,  0.0715,  0.0578,  0.0460,  0.0540,  0.0519,  0.0455,  0.0382,\n",
       "          0.0397,  0.0411,  0.0357,  0.0304,  0.0302,  0.0390,  0.1178,  0.0957,\n",
       "          0.0812,  0.0725,  0.0906,  0.0962,  0.0868,  0.0813,  0.0801,  0.0818,\n",
       "          0.0671,  0.0638,  0.0685,  0.0946]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to concatenate context and embedding word\n",
    "torch.cat([embeddings[:, index], feature_mean], dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
