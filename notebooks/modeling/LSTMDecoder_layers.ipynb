{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Long Short Term Memory Decoder__\n",
    "\n",
    "### __Deep Learning__\n",
    "\n",
    "#### __Project: Image Captioning with Visual Attention__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.environ[\"PYTHONPATH\"])\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scripts.data_loading as dl\n",
    "import scripts.data_processing as dp\n",
    "from scripts import model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "plt.rcParams[\"image.cmap\"] = \"plasma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.51s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train = dl.CocoCaptions(\n",
    "    dl.DATASET_PATHS[dl.DatasetType.TRAIN],\n",
    "    dp.VGGNET_PREPROCESSING_PIPELINE,\n",
    "    dp.TextPipeline(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_loader = dl.CocoLoader(coco_train, batch_size=2, num_workers=1)\n",
    "it = iter(coco_loader)\n",
    "image_batch, caption_batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.VGG19Encoder()\n",
    "feature_maps, feature_mean = encoder.forward(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = model.LSTMDecoder(\n",
    "    num_embeddings=len(coco_train.target_transform.vocabulary),\n",
    "    embedding_dim=8,\n",
    "    encoder_dim=feature_mean.shape[-1],\n",
    "    decoder_dim=16,\n",
    "    attention_dim=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = decoder.word_embedding(caption_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded caption shape = torch.Size([51])\n",
      "Embedding shape = torch.Size([51, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"One-hot encoded caption shape = {caption_batch[0].shape}\")\n",
    "print(f\"Embedding shape = {embeddings[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10000,    12,    78,    22,    34,   850,    31,     4,     0,   182,\n",
      "            1,  1421,    65,     2,     0,     8,   283,  1486,     0,    34,\n",
      "          204,     9,  1584,    47,    34,   924,     1,    34,  1118,     5,\n",
      "          133,   167,    62,    34,  1186,     4,   121,     4,    36,     2,\n",
      "          244,     6,    12,  1186,     1,   206,     6,   314, 10002,   139,\n",
      "        10001])\n",
      "tensor([[ 1.0778, -0.0469,  0.1941, -0.2538, -0.8269,  0.1713,  0.5453,  0.1663],\n",
      "        [ 0.8444, -0.1235,  2.5719,  0.1893, -0.6015, -0.4761, -1.3315,  1.9284],\n",
      "        [-0.4916, -0.7716,  0.5826, -1.1466,  0.0599, -1.0457,  1.5602, -0.2518],\n",
      "        [ 0.2387, -0.0527, -0.9759,  0.3773, -0.2878, -1.0109,  0.8171,  1.3285],\n",
      "        [ 0.1028,  1.3981, -1.0535,  0.6148,  1.0786,  1.3067,  0.4572, -0.3867],\n",
      "        [-1.2201,  1.2055, -0.3191,  0.2431, -1.0352, -0.7764,  1.2666, -1.3419],\n",
      "        [-0.5972,  2.3009,  0.4261,  0.1007,  1.6311,  0.9198, -0.7458, -0.7728],\n",
      "        [-0.8278, -1.3160, -0.2625, -1.5671,  0.9839,  0.3513, -0.8460,  0.3508],\n",
      "        [-0.2410,  0.2762,  0.4883,  0.0336, -0.7119,  0.0274, -0.1136, -1.5017],\n",
      "        [-2.2954,  1.5275, -1.5167, -0.2235, -1.2872,  1.2102,  0.1094, -0.9198],\n",
      "        [-0.9359,  0.4462,  0.1966, -1.3825, -0.1522,  0.2046,  0.5457,  1.8823],\n",
      "        [ 0.7282,  0.0818,  1.4679, -1.1165,  1.4729, -1.6799,  0.0276,  1.9505],\n",
      "        [ 0.1820, -0.2714,  1.8504,  1.1690,  1.1365,  0.1148, -0.5762,  0.0777],\n",
      "        [ 0.3609, -0.0726,  0.8679, -0.3908, -0.0070, -1.4212,  0.3929,  0.1898],\n",
      "        [-0.2410,  0.2762,  0.4883,  0.0336, -0.7119,  0.0274, -0.1136, -1.5017],\n",
      "        [ 0.4575,  1.3246,  0.5656,  1.6557, -0.2688,  0.9599,  1.4247,  1.1516],\n",
      "        [ 0.3381, -0.6228,  0.5805, -0.3814, -1.3231, -1.2445, -0.2851,  0.4848],\n",
      "        [-1.3547, -1.0466,  1.2629,  1.1262,  0.5366, -0.6711, -0.4055, -0.4209],\n",
      "        [-0.2410,  0.2762,  0.4883,  0.0336, -0.7119,  0.0274, -0.1136, -1.5017],\n",
      "        [ 0.1028,  1.3981, -1.0535,  0.6148,  1.0786,  1.3067,  0.4572, -0.3867],\n",
      "        [ 0.1843,  0.8216, -0.9609,  0.8217,  1.4993, -0.7344, -0.5716, -1.0659],\n",
      "        [ 0.1981,  0.2730,  0.1310, -0.0558, -0.3966,  0.2212,  0.0464,  0.8709],\n",
      "        [ 1.8448, -1.6229,  2.5219,  1.0686, -1.9307,  0.1032, -1.5466, -1.6901],\n",
      "        [ 1.0062, -1.3293,  0.4099,  0.5219, -1.6039, -1.3973, -0.4424, -1.3510],\n",
      "        [ 0.1028,  1.3981, -1.0535,  0.6148,  1.0786,  1.3067,  0.4572, -0.3867],\n",
      "        [ 1.1123, -1.0651, -1.7439,  0.7878, -2.5122, -1.3923,  0.3762, -1.0824],\n",
      "        [-0.9359,  0.4462,  0.1966, -1.3825, -0.1522,  0.2046,  0.5457,  1.8823],\n",
      "        [ 0.1028,  1.3981, -1.0535,  0.6148,  1.0786,  1.3067,  0.4572, -0.3867],\n",
      "        [-0.9490, -0.0095,  0.6750,  0.2871, -0.0076, -0.1235, -0.1677,  0.5440],\n",
      "        [ 1.8940, -0.1738,  0.0846, -0.6670,  0.1616, -1.4257,  0.5628, -1.3179],\n",
      "        [ 0.4402,  0.4989,  0.1642, -0.5381, -0.3734,  1.3593,  0.6279,  0.4288],\n",
      "        [ 0.2077,  0.9020, -0.2066,  0.6763,  1.2086, -0.0827, -1.4414,  0.5928],\n",
      "        [-1.0536,  1.0964, -0.1907,  0.0039, -2.0799,  1.6473, -0.5959, -0.7539],\n",
      "        [ 0.1028,  1.3981, -1.0535,  0.6148,  1.0786,  1.3067,  0.4572, -0.3867],\n",
      "        [ 0.3909, -0.1542, -0.2408,  0.5156, -0.4477,  0.5217,  0.0370, -0.1336],\n",
      "        [-0.8278, -1.3160, -0.2625, -1.5671,  0.9839,  0.3513, -0.8460,  0.3508],\n",
      "        [-0.8254, -1.3342, -0.5611,  0.0237, -0.8437, -1.1220,  0.7050, -0.0051],\n",
      "        [-0.8278, -1.3160, -0.2625, -1.5671,  0.9839,  0.3513, -0.8460,  0.3508],\n",
      "        [-1.6819,  0.4579,  0.7461,  0.5884,  0.9923, -1.1330, -0.5965,  1.0952],\n",
      "        [ 0.3609, -0.0726,  0.8679, -0.3908, -0.0070, -1.4212,  0.3929,  0.1898],\n",
      "        [-0.0886,  0.0985,  1.5832, -1.1435, -0.0438, -1.4480,  0.8933,  0.6726],\n",
      "        [ 0.9077, -2.0307,  1.0320,  0.8506,  0.6497, -0.0346,  0.0446,  0.5534],\n",
      "        [ 0.8444, -0.1235,  2.5719,  0.1893, -0.6015, -0.4761, -1.3315,  1.9284],\n",
      "        [ 0.3909, -0.1542, -0.2408,  0.5156, -0.4477,  0.5217,  0.0370, -0.1336],\n",
      "        [-0.9359,  0.4462,  0.1966, -1.3825, -0.1522,  0.2046,  0.5457,  1.8823],\n",
      "        [ 0.6754,  0.9199,  1.3756, -0.7564, -0.3154, -1.5603, -1.2075, -0.4183],\n",
      "        [ 0.9077, -2.0307,  1.0320,  0.8506,  0.6497, -0.0346,  0.0446,  0.5534],\n",
      "        [-1.8584, -0.5976,  0.1472, -0.2130, -0.3115,  1.5247,  0.7519,  1.0864],\n",
      "        [-0.2141,  0.3116,  0.4834,  0.5653,  2.2165,  1.2090, -0.6702, -1.2365],\n",
      "        [ 2.1459, -0.2401,  1.5280, -0.0339, -1.2205,  0.9436, -0.5260, -0.0462],\n",
      "        [ 1.0397, -1.2835,  0.1092,  0.3504,  0.5646,  2.0723, -0.0058, -0.2355]],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(caption_batch[0])\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial h shape = torch.Size([2, 16])\n",
      "Initial c shape = torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "h = decoder.init_h(feature_mean)\n",
    "c = decoder.init_c(feature_mean)\n",
    "\n",
    "print(f\"Initial h shape = {h.shape}\")\n",
    "print(f\"Initial c shape = {c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1671, -0.2366,  0.0020,  0.1604,  0.0024, -0.1476,  0.0745,  0.2381,\n",
      "         0.0619,  0.3908,  0.1211,  0.2242,  0.3448,  0.0006,  0.0996,  0.1740],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.1581,  0.1302,  0.0385, -0.0008, -0.1579,  0.3189,  0.2711, -0.0877,\n",
      "        -0.0498, -0.0392, -0.0884,  0.1122, -0.1119, -0.2567,  0.0209,  0.3199],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Initial h, c of LSTM computed by MLP(feature_maps_mean)\n",
    "print(h[0])\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0397, -1.2835,  0.1092,  0.3504,  0.5646,  2.0723, -0.0058, -0.2355],\n",
       "        [ 1.0397, -1.2835,  0.1092,  0.3504,  0.5646,  2.0723, -0.0058, -0.2355]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get word embeddings of words at particular index of a caption in batch\n",
    "index = 50\n",
    "embeddings[:, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1412, 0.1195, 0.1757, 0.1956, 0.2014, 0.1619, 0.1296, 0.1212, 0.1625,\n",
       "         0.2444, 0.2788, 0.3305, 0.3097, 0.3634, 0.2017, 0.1454, 0.0949, 0.0646,\n",
       "         0.0738, 0.0580, 0.0685, 0.0834, 0.1497, 0.3198, 0.2564, 0.2706, 0.2274,\n",
       "         0.2668, 0.4305, 0.2778, 0.3106, 0.2719, 0.2167, 0.0923, 0.0908, 0.1187,\n",
       "         0.3236, 0.6264, 0.3948, 0.4090, 0.3418, 0.3622, 0.3230, 0.1912, 0.2707,\n",
       "         0.2215, 0.1806, 0.0852, 0.0931, 0.1090, 0.2908, 0.4428, 0.1921, 0.2183,\n",
       "         0.2172, 0.3397, 0.3572, 0.2309, 0.2297, 0.1774, 0.2011, 0.1361, 0.1507,\n",
       "         0.1538, 0.2483, 0.2350, 0.1305, 0.1665, 0.2978, 0.4957, 0.3393, 0.1802,\n",
       "         0.1848, 0.1314, 0.2549, 0.3474, 0.3141, 0.2434, 0.2089, 0.1747, 0.2000,\n",
       "         0.2210, 0.3853, 0.5794, 0.2008, 0.1367, 0.1783, 0.1296, 0.2880, 0.4784,\n",
       "         0.5109, 0.4420, 0.3456, 0.3144, 0.3219, 0.3269, 0.3614, 0.5044, 0.2522,\n",
       "         0.1661, 0.2265, 0.1435, 0.2713, 0.4259, 0.4878, 0.4517, 0.3450, 0.2899,\n",
       "         0.2741, 0.2950, 0.3401, 0.4399, 0.2932, 0.2313, 0.3534, 0.2611, 0.3260,\n",
       "         0.3536, 0.4130, 0.4175, 0.3646, 0.3397, 0.3101, 0.3242, 0.3097, 0.3636,\n",
       "         0.2150, 0.1634, 0.3246, 0.2434, 0.2508, 0.2482, 0.2858, 0.2830, 0.2809,\n",
       "         0.2907, 0.2592, 0.2438, 0.2179, 0.2397, 0.1872, 0.1783, 0.3992, 0.3072,\n",
       "         0.2603, 0.2323, 0.2626, 0.2672, 0.2824, 0.2967, 0.3095, 0.3110, 0.2057,\n",
       "         0.1938, 0.1669, 0.1667, 0.3848, 0.2800, 0.2690, 0.2479, 0.2765, 0.2835,\n",
       "         0.2868, 0.3166, 0.3409, 0.3610, 0.2152, 0.1754, 0.0764, 0.0413, 0.1209,\n",
       "         0.0874, 0.1069, 0.1267, 0.1686, 0.1794, 0.1630, 0.1515, 0.1526, 0.1545,\n",
       "         0.0859, 0.0868, 0.1290, 0.0643, 0.1268, 0.1148, 0.1455, 0.1668, 0.2439,\n",
       "         0.2470, 0.1805, 0.1701, 0.1976, 0.2303, 0.1296, 0.1079],\n",
       "        [0.1741, 0.0801, 0.1035, 0.1055, 0.1187, 0.1308, 0.1595, 0.1957, 0.2268,\n",
       "         0.2774, 0.3237, 0.4506, 0.3448, 0.3125, 0.0962, 0.0501, 0.0558, 0.0482,\n",
       "         0.0534, 0.0530, 0.0617, 0.0883, 0.1416, 0.2479, 0.3094, 0.3759, 0.2664,\n",
       "         0.2388, 0.1373, 0.0582, 0.0966, 0.0773, 0.0841, 0.0906, 0.1046, 0.1501,\n",
       "         0.2111, 0.4186, 0.4966, 0.5952, 0.4593, 0.3463, 0.1030, 0.0424, 0.0969,\n",
       "         0.0788, 0.0898, 0.1254, 0.1398, 0.1278, 0.1440, 0.2580, 0.2966, 0.2902,\n",
       "         0.1905, 0.1361, 0.0979, 0.0600, 0.1240, 0.1083, 0.1269, 0.2019, 0.3088,\n",
       "         0.3049, 0.1863, 0.2683, 0.2083, 0.1237, 0.0847, 0.0728, 0.0773, 0.0530,\n",
       "         0.1156, 0.1271, 0.1494, 0.3874, 0.7495, 0.7648, 0.3806, 0.1225, 0.0825,\n",
       "         0.0438, 0.0417, 0.0376, 0.0593, 0.0435, 0.0837, 0.1135, 0.1880, 0.5625,\n",
       "         0.9928, 1.0152, 0.6882, 0.1317, 0.0747, 0.0426, 0.0415, 0.0372, 0.0493,\n",
       "         0.0446, 0.0686, 0.0931, 0.2053, 0.6412, 1.1315, 1.0449, 0.7445, 0.1543,\n",
       "         0.0766, 0.0458, 0.0475, 0.0528, 0.0557, 0.0435, 0.0518, 0.0532, 0.1462,\n",
       "         0.3874, 0.6900, 0.5534, 0.3410, 0.1292, 0.0867, 0.0532, 0.0529, 0.0566,\n",
       "         0.0703, 0.0475, 0.0470, 0.0439, 0.0763, 0.1198, 0.1719, 0.1570, 0.1285,\n",
       "         0.0853, 0.0671, 0.0506, 0.0449, 0.0547, 0.0812, 0.0529, 0.0678, 0.0692,\n",
       "         0.0886, 0.1089, 0.1234, 0.1141, 0.0827, 0.0474, 0.0320, 0.0274, 0.0303,\n",
       "         0.0440, 0.1107, 0.0799, 0.0865, 0.0746, 0.0729, 0.0720, 0.0695, 0.0527,\n",
       "         0.0390, 0.0287, 0.0257, 0.0288, 0.0360, 0.0513, 0.0923, 0.0715, 0.0578,\n",
       "         0.0460, 0.0540, 0.0519, 0.0455, 0.0382, 0.0397, 0.0411, 0.0357, 0.0304,\n",
       "         0.0302, 0.0390, 0.1178, 0.0957, 0.0812, 0.0725, 0.0906, 0.0962, 0.0868,\n",
       "         0.0813, 0.0801, 0.0818, 0.0671, 0.0638, 0.0685, 0.0946]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0397, -1.2835,  0.1092,  0.3504,  0.5646,  2.0723, -0.0058, -0.2355,\n",
       "          0.1412,  0.1195,  0.1757,  0.1956,  0.2014,  0.1619,  0.1296,  0.1212,\n",
       "          0.1625,  0.2444,  0.2788,  0.3305,  0.3097,  0.3634,  0.2017,  0.1454,\n",
       "          0.0949,  0.0646,  0.0738,  0.0580,  0.0685,  0.0834,  0.1497,  0.3198,\n",
       "          0.2564,  0.2706,  0.2274,  0.2668,  0.4305,  0.2778,  0.3106,  0.2719,\n",
       "          0.2167,  0.0923,  0.0908,  0.1187,  0.3236,  0.6264,  0.3948,  0.4090,\n",
       "          0.3418,  0.3622,  0.3230,  0.1912,  0.2707,  0.2215,  0.1806,  0.0852,\n",
       "          0.0931,  0.1090,  0.2908,  0.4428,  0.1921,  0.2183,  0.2172,  0.3397,\n",
       "          0.3572,  0.2309,  0.2297,  0.1774,  0.2011,  0.1361,  0.1507,  0.1538,\n",
       "          0.2483,  0.2350,  0.1305,  0.1665,  0.2978,  0.4957,  0.3393,  0.1802,\n",
       "          0.1848,  0.1314,  0.2549,  0.3474,  0.3141,  0.2434,  0.2089,  0.1747,\n",
       "          0.2000,  0.2210,  0.3853,  0.5794,  0.2008,  0.1367,  0.1783,  0.1296,\n",
       "          0.2880,  0.4784,  0.5109,  0.4420,  0.3456,  0.3144,  0.3219,  0.3269,\n",
       "          0.3614,  0.5044,  0.2522,  0.1661,  0.2265,  0.1435,  0.2713,  0.4259,\n",
       "          0.4878,  0.4517,  0.3450,  0.2899,  0.2741,  0.2950,  0.3401,  0.4399,\n",
       "          0.2932,  0.2313,  0.3534,  0.2611,  0.3260,  0.3536,  0.4130,  0.4175,\n",
       "          0.3646,  0.3397,  0.3101,  0.3242,  0.3097,  0.3636,  0.2150,  0.1634,\n",
       "          0.3246,  0.2434,  0.2508,  0.2482,  0.2858,  0.2830,  0.2809,  0.2907,\n",
       "          0.2592,  0.2438,  0.2179,  0.2397,  0.1872,  0.1783,  0.3992,  0.3072,\n",
       "          0.2603,  0.2323,  0.2626,  0.2672,  0.2824,  0.2967,  0.3095,  0.3110,\n",
       "          0.2057,  0.1938,  0.1669,  0.1667,  0.3848,  0.2800,  0.2690,  0.2479,\n",
       "          0.2765,  0.2835,  0.2868,  0.3166,  0.3409,  0.3610,  0.2152,  0.1754,\n",
       "          0.0764,  0.0413,  0.1209,  0.0874,  0.1069,  0.1267,  0.1686,  0.1794,\n",
       "          0.1630,  0.1515,  0.1526,  0.1545,  0.0859,  0.0868,  0.1290,  0.0643,\n",
       "          0.1268,  0.1148,  0.1455,  0.1668,  0.2439,  0.2470,  0.1805,  0.1701,\n",
       "          0.1976,  0.2303,  0.1296,  0.1079],\n",
       "        [ 1.0397, -1.2835,  0.1092,  0.3504,  0.5646,  2.0723, -0.0058, -0.2355,\n",
       "          0.1741,  0.0801,  0.1035,  0.1055,  0.1187,  0.1308,  0.1595,  0.1957,\n",
       "          0.2268,  0.2774,  0.3237,  0.4506,  0.3448,  0.3125,  0.0962,  0.0501,\n",
       "          0.0558,  0.0482,  0.0534,  0.0530,  0.0617,  0.0883,  0.1416,  0.2479,\n",
       "          0.3094,  0.3759,  0.2664,  0.2388,  0.1373,  0.0582,  0.0966,  0.0773,\n",
       "          0.0841,  0.0906,  0.1046,  0.1501,  0.2111,  0.4186,  0.4966,  0.5952,\n",
       "          0.4593,  0.3463,  0.1030,  0.0424,  0.0969,  0.0788,  0.0898,  0.1254,\n",
       "          0.1398,  0.1278,  0.1440,  0.2580,  0.2966,  0.2902,  0.1905,  0.1361,\n",
       "          0.0979,  0.0600,  0.1240,  0.1083,  0.1269,  0.2019,  0.3088,  0.3049,\n",
       "          0.1863,  0.2683,  0.2083,  0.1237,  0.0847,  0.0728,  0.0773,  0.0530,\n",
       "          0.1156,  0.1271,  0.1494,  0.3874,  0.7495,  0.7648,  0.3806,  0.1225,\n",
       "          0.0825,  0.0438,  0.0417,  0.0376,  0.0593,  0.0435,  0.0837,  0.1135,\n",
       "          0.1880,  0.5625,  0.9928,  1.0152,  0.6882,  0.1317,  0.0747,  0.0426,\n",
       "          0.0415,  0.0372,  0.0493,  0.0446,  0.0686,  0.0931,  0.2053,  0.6412,\n",
       "          1.1315,  1.0449,  0.7445,  0.1543,  0.0766,  0.0458,  0.0475,  0.0528,\n",
       "          0.0557,  0.0435,  0.0518,  0.0532,  0.1462,  0.3874,  0.6900,  0.5534,\n",
       "          0.3410,  0.1292,  0.0867,  0.0532,  0.0529,  0.0566,  0.0703,  0.0475,\n",
       "          0.0470,  0.0439,  0.0763,  0.1198,  0.1719,  0.1570,  0.1285,  0.0853,\n",
       "          0.0671,  0.0506,  0.0449,  0.0547,  0.0812,  0.0529,  0.0678,  0.0692,\n",
       "          0.0886,  0.1089,  0.1234,  0.1141,  0.0827,  0.0474,  0.0320,  0.0274,\n",
       "          0.0303,  0.0440,  0.1107,  0.0799,  0.0865,  0.0746,  0.0729,  0.0720,\n",
       "          0.0695,  0.0527,  0.0390,  0.0287,  0.0257,  0.0288,  0.0360,  0.0513,\n",
       "          0.0923,  0.0715,  0.0578,  0.0460,  0.0540,  0.0519,  0.0455,  0.0382,\n",
       "          0.0397,  0.0411,  0.0357,  0.0304,  0.0302,  0.0390,  0.1178,  0.0957,\n",
       "          0.0812,  0.0725,  0.0906,  0.0962,  0.0868,  0.0813,  0.0801,  0.0818,\n",
       "          0.0671,  0.0638,  0.0685,  0.0946]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to concatenate context and embedding word\n",
    "torch.cat([embeddings[:, index], feature_mean], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, attention_scores = decoder.forward(feature_maps, feature_mean, caption_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 51])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of predicted words == caption_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2, 10004])\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random guess prediction probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.softmax(predictions, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.0981e-05, 7.1937e-05, 1.0210e-04, 1.2367e-04, 1.1758e-04, 7.6954e-05,\n",
       "        1.2097e-04, 1.1994e-04, 9.5205e-05, 1.0197e-04, 1.1928e-04, 1.6873e-04,\n",
       "        1.2307e-04, 8.8403e-05, 7.0400e-05, 6.1201e-05, 7.2279e-05, 8.3104e-05,\n",
       "        8.7575e-05, 1.4165e-04, 1.0737e-04, 5.8038e-05, 9.8186e-05, 9.2949e-05,\n",
       "        1.0736e-04, 8.1271e-05, 1.2535e-04, 1.0711e-04, 1.0878e-04, 1.5737e-04,\n",
       "        1.2322e-04, 9.5206e-05, 1.2395e-04, 8.1855e-05, 1.5322e-04, 1.1930e-04,\n",
       "        7.1873e-05, 1.0991e-04, 1.0167e-04, 8.6898e-05, 6.0001e-05, 1.0933e-04,\n",
       "        1.5482e-04, 6.1983e-05, 1.4360e-04, 6.6817e-05, 1.0841e-04, 9.7156e-05,\n",
       "        9.6314e-05, 1.2056e-04, 1.4362e-04, 8.9042e-05, 1.1316e-04, 1.2110e-04,\n",
       "        9.8696e-05, 1.2230e-04, 7.3913e-05, 7.5212e-05, 1.1653e-04, 1.0285e-04,\n",
       "        1.0164e-04, 6.3000e-05, 1.3507e-04, 1.7154e-04, 7.1862e-05, 8.3223e-05,\n",
       "        1.0052e-04, 1.0690e-04, 9.3785e-05, 1.2631e-04, 9.4175e-05, 8.3557e-05,\n",
       "        6.5326e-05, 1.5785e-04, 7.6731e-05, 7.6077e-05, 8.0187e-05, 1.5858e-04,\n",
       "        1.0838e-04, 1.5528e-04, 1.2359e-04, 7.8583e-05, 9.0969e-05, 8.0962e-05,\n",
       "        9.7111e-05, 7.9156e-05, 1.1699e-04, 9.8210e-05, 9.1152e-05, 1.1111e-04,\n",
       "        9.4827e-05, 1.4474e-04, 8.3599e-05, 1.3101e-04, 9.7920e-05, 1.1986e-04,\n",
       "        8.9323e-05, 1.4209e-04, 9.2561e-05, 1.4008e-04],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0, 0, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.996001599360256e-05"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 10_004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 2, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0019, 0.0023, 0.0019, 0.0020, 0.0023, 0.0020, 0.0018, 0.0019, 0.0025,\n",
       "        0.0018, 0.0019, 0.0019, 0.0017, 0.0021, 0.0010, 0.0018, 0.0015, 0.0020,\n",
       "        0.0018, 0.0018, 0.0012, 0.0019, 0.0023, 0.0027, 0.0019, 0.0019, 0.0024,\n",
       "        0.0030, 0.0024, 0.0015, 0.0018, 0.0018, 0.0019, 0.0020, 0.0019, 0.0017,\n",
       "        0.0031, 0.0018, 0.0018, 0.0019, 0.0019, 0.0025, 0.0019, 0.0018, 0.0020,\n",
       "        0.0019, 0.0023, 0.0019, 0.0013, 0.0018, 0.0018, 0.0018, 0.0018, 0.0020,\n",
       "        0.0019, 0.0018, 0.0017, 0.0018, 0.0022, 0.0020, 0.0018, 0.0019, 0.0019,\n",
       "        0.0018, 0.0025, 0.0019, 0.0018, 0.0018, 0.0016, 0.0022, 0.0024, 0.0019,\n",
       "        0.0019, 0.0020, 0.0021, 0.0023, 0.0016, 0.0019, 0.0014, 0.0022, 0.0018,\n",
       "        0.0019, 0.0018, 0.0020, 0.0018, 0.0018, 0.0018, 0.0019, 0.0016, 0.0020,\n",
       "        0.0015, 0.0018, 0.0027, 0.0023, 0.0019, 0.0019, 0.0017, 0.0017, 0.0022,\n",
       "        0.0019, 0.0015, 0.0020, 0.0018, 0.0019, 0.0018, 0.0019, 0.0026, 0.0019,\n",
       "        0.0026, 0.0021, 0.0018, 0.0018, 0.0017, 0.0018, 0.0018, 0.0018, 0.0030,\n",
       "        0.0019, 0.0021, 0.0019, 0.0018, 0.0018, 0.0018, 0.0018, 0.0020, 0.0014,\n",
       "        0.0019, 0.0021, 0.0019, 0.0017, 0.0020, 0.0017, 0.0019, 0.0019, 0.0026,\n",
       "        0.0019, 0.0018, 0.0018, 0.0024, 0.0018, 0.0019, 0.0020, 0.0018, 0.0018,\n",
       "        0.0022, 0.0018, 0.0024, 0.0025, 0.0018, 0.0019, 0.0019, 0.0023, 0.0021,\n",
       "        0.0020, 0.0021, 0.0025, 0.0018, 0.0018, 0.0019, 0.0030, 0.0018, 0.0018,\n",
       "        0.0019, 0.0030, 0.0020, 0.0019, 0.0018, 0.0018, 0.0023, 0.0019, 0.0027,\n",
       "        0.0018, 0.0019, 0.0022, 0.0020, 0.0013, 0.0019, 0.0019, 0.0017, 0.0015,\n",
       "        0.0018, 0.0023, 0.0018, 0.0019, 0.0018, 0.0018, 0.0019, 0.0016, 0.0018,\n",
       "        0.0020, 0.0018, 0.0027, 0.0020, 0.0019, 0.0018, 0.0010, 0.0019, 0.0018,\n",
       "        0.0018, 0.0026, 0.0027, 0.0019, 0.0018, 0.0018, 0.0028, 0.0019, 0.0027,\n",
       "        0.0012, 0.0018, 0.0013, 0.0020, 0.0019, 0.0020, 0.0012, 0.0018, 0.0018,\n",
       "        0.0026, 0.0015, 0.0018, 0.0017, 0.0023, 0.0017, 0.0019, 0.0014, 0.0020,\n",
       "        0.0019, 0.0018, 0.0015, 0.0018, 0.0021, 0.0019, 0.0018, 0.0019, 0.0017,\n",
       "        0.0017, 0.0014, 0.0018, 0.0018, 0.0026, 0.0018, 0.0020, 0.0023, 0.0019,\n",
       "        0.0025, 0.0020, 0.0018, 0.0023, 0.0021, 0.0019, 0.0017, 0.0021, 0.0038,\n",
       "        0.0018, 0.0019, 0.0018, 0.0020, 0.0019, 0.0010, 0.0016, 0.0017, 0.0018,\n",
       "        0.0019, 0.0021, 0.0013, 0.0015, 0.0022, 0.0018, 0.0021, 0.0021, 0.0018,\n",
       "        0.0026, 0.0018, 0.0019, 0.0017, 0.0018, 0.0018, 0.0018, 0.0018, 0.0021,\n",
       "        0.0028, 0.0018, 0.0021, 0.0018, 0.0018, 0.0019, 0.0027, 0.0014, 0.0019,\n",
       "        0.0018, 0.0018, 0.0018, 0.0018, 0.0025, 0.0028, 0.0019, 0.0018, 0.0018,\n",
       "        0.0018, 0.0027, 0.0018, 0.0019, 0.0020, 0.0018, 0.0019, 0.0018, 0.0017,\n",
       "        0.0018, 0.0018, 0.0012, 0.0017, 0.0019, 0.0022, 0.0019, 0.0021, 0.0018,\n",
       "        0.0017, 0.0016, 0.0019, 0.0020, 0.0018, 0.0014, 0.0017, 0.0018, 0.0019,\n",
       "        0.0020, 0.0027, 0.0022, 0.0020, 0.0020, 0.0020, 0.0025, 0.0020, 0.0021,\n",
       "        0.0023, 0.0018, 0.0022, 0.0018, 0.0019, 0.0019, 0.0017, 0.0013, 0.0022,\n",
       "        0.0014, 0.0020, 0.0021, 0.0019, 0.0017, 0.0019, 0.0025, 0.0025, 0.0015,\n",
       "        0.0019, 0.0014, 0.0018, 0.0018, 0.0023, 0.0013, 0.0026, 0.0018, 0.0024,\n",
       "        0.0026, 0.0027, 0.0015, 0.0019, 0.0019, 0.0026, 0.0020, 0.0018, 0.0020,\n",
       "        0.0018, 0.0019, 0.0026, 0.0013, 0.0028, 0.0032, 0.0018, 0.0019, 0.0017,\n",
       "        0.0018, 0.0019, 0.0015, 0.0019, 0.0021, 0.0029, 0.0022, 0.0019, 0.0017,\n",
       "        0.0021, 0.0023, 0.0024, 0.0029, 0.0020, 0.0021, 0.0025, 0.0019, 0.0021,\n",
       "        0.0027, 0.0019, 0.0018, 0.0017, 0.0017, 0.0017, 0.0018, 0.0018, 0.0015,\n",
       "        0.0019, 0.0020, 0.0018, 0.0018, 0.0018, 0.0022, 0.0019, 0.0019, 0.0015,\n",
       "        0.0018, 0.0019, 0.0013, 0.0020, 0.0022, 0.0018, 0.0017, 0.0019, 0.0019,\n",
       "        0.0020, 0.0015, 0.0018, 0.0018, 0.0017, 0.0018, 0.0018, 0.0020, 0.0019,\n",
       "        0.0020, 0.0020, 0.0015, 0.0019, 0.0019, 0.0021, 0.0018, 0.0019, 0.0017,\n",
       "        0.0023, 0.0017, 0.0019, 0.0018, 0.0018, 0.0018, 0.0014, 0.0018, 0.0014,\n",
       "        0.0015, 0.0038, 0.0018, 0.0018, 0.0018, 0.0020, 0.0015, 0.0027, 0.0017,\n",
       "        0.0028, 0.0026, 0.0015, 0.0020, 0.0019, 0.0016, 0.0018, 0.0019, 0.0022,\n",
       "        0.0019, 0.0015, 0.0018, 0.0020, 0.0022, 0.0021, 0.0017, 0.0018, 0.0018,\n",
       "        0.0018, 0.0019, 0.0021, 0.0022, 0.0018, 0.0018, 0.0009, 0.0021, 0.0035,\n",
       "        0.0021, 0.0019, 0.0019, 0.0014, 0.0021, 0.0019, 0.0026, 0.0021, 0.0018,\n",
       "        0.0027, 0.0011, 0.0018, 0.0027, 0.0019, 0.0026, 0.0029, 0.0018, 0.0020,\n",
       "        0.0024, 0.0019, 0.0021, 0.0018, 0.0015, 0.0018, 0.0017, 0.0016],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001953125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
