{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Long Short Term Memory Decoder__\n",
    "\n",
    "### __Deep Learning__\n",
    "\n",
    "#### __Project: Image Captioning with Visual Attention__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.environ[\"PYTHONPATH\"])\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scripts.data_loading as dl\n",
    "import scripts.data_preprocessing as dp\n",
    "from scripts import model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "plt.rcParams[\"image.cmap\"] = \"plasma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.98s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train = dl.CocoCaptions(\n",
    "    dl.TRAINING_DATASET_PATHS[dl.DatasetType.TRAIN],\n",
    "    dp.VGGNET_PREPROCESSING_PIPELINE,\n",
    "    dp.TextPipeline(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_loader = dl.CocoLoader(coco_train, batch_size=2, num_workers=1)\n",
    "it = iter(coco_loader)\n",
    "image_batch, caption_batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.VGG19Encoder()\n",
    "feature_maps, feature_mean = encoder.forward(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = model.LSTMDecoder(\n",
    "    num_embeddings=len(coco_train.target_transform.vocabulary),\n",
    "    embedding_dim=8,\n",
    "    encoder_dim=feature_mean.shape[-1],\n",
    "    decoder_dim=16,\n",
    "    attention_dim=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = decoder.word_embedding(caption_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded caption shape = torch.Size([51])\n",
      "Embedding shape = torch.Size([51, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"One-hot encoded caption shape = {caption_batch[0].shape}\")\n",
    "print(f\"Embedding shape = {embeddings[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10000,    12,    78,    22,    34,   850,    31,     4,     0,   182,\n",
      "            1,  1421,    65,     2,     0,     8,   283,  1486,     0,    34,\n",
      "          204,     9,  1584,    47,    34,   924,     1,    34,  1118,     5,\n",
      "          133,   167,    62,    34,  1186,     4,   121,     4,    36,     2,\n",
      "          244,     6,    12,  1186,     1,   206,     6,   314, 10002,   139,\n",
      "        10001])\n",
      "tensor([[-2.3225e+00, -4.6404e-01,  1.1217e+00, -1.9029e+00, -4.7541e-01,\n",
      "         -3.0222e+00, -2.6728e-02,  1.6189e-01],\n",
      "        [ 9.2422e-01,  1.5713e-01,  1.1718e-01,  6.4099e-01,  4.6515e-01,\n",
      "         -6.5121e-01, -1.0691e+00,  1.4528e+00],\n",
      "        [ 1.3126e+00,  3.5706e-01, -3.4324e-01, -1.1548e+00, -4.2286e-01,\n",
      "         -1.0998e+00,  4.1202e-01,  9.4997e-01],\n",
      "        [ 3.8166e-01,  1.4431e+00, -7.4698e-01,  7.4755e-02, -1.6625e+00,\n",
      "         -1.0354e+00,  1.2164e+00, -7.2012e-01],\n",
      "        [ 1.5417e+00,  1.1712e+00, -6.5890e-01, -1.3323e+00, -4.1057e-01,\n",
      "         -1.5926e+00,  3.9475e-02, -3.5899e-01],\n",
      "        [ 9.7698e-01,  2.6103e-01, -2.0161e+00, -1.0386e+00, -4.9413e-01,\n",
      "          1.5611e-01,  2.1363e+00,  7.3807e-01],\n",
      "        [ 1.2102e-01, -1.3975e+00,  1.3168e+00,  7.0017e-01, -1.6861e+00,\n",
      "         -1.3759e+00,  2.3285e-01,  1.2476e+00],\n",
      "        [-3.5619e-01, -1.1325e+00,  6.4733e-01,  1.7356e+00, -5.8374e-01,\n",
      "          1.6300e+00,  1.1204e+00,  2.4000e-02],\n",
      "        [-7.5266e-01, -2.1692e-01,  7.2461e-01, -2.0918e+00, -7.4598e-01,\n",
      "          7.2764e-01,  1.7699e-02, -8.9071e-01],\n",
      "        [-3.6125e-01,  7.0574e-01,  2.8646e-01, -5.9618e-01, -4.8317e-02,\n",
      "         -1.1183e+00,  1.0823e+00, -4.5677e-01],\n",
      "        [ 1.4545e+00, -1.3275e+00,  2.1460e+00,  4.3348e-01, -7.6122e-01,\n",
      "          2.6432e-01,  1.9517e+00,  1.6368e-01],\n",
      "        [ 9.8397e-01, -2.7927e-01,  2.2858e-01,  2.2010e-01, -1.2223e+00,\n",
      "         -2.7235e-01,  1.2210e+00, -2.3847e+00],\n",
      "        [-3.7413e-01,  8.7746e-01,  1.8942e+00, -2.3434e+00, -4.6877e-01,\n",
      "          1.4444e+00, -5.4814e-01,  9.7410e-01],\n",
      "        [-1.4086e+00, -1.4212e+00, -1.0490e+00, -8.6374e-01, -1.7935e+00,\n",
      "          1.7698e+00,  1.0187e+00,  5.8245e-01],\n",
      "        [-7.5266e-01, -2.1692e-01,  7.2461e-01, -2.0918e+00, -7.4598e-01,\n",
      "          7.2764e-01,  1.7699e-02, -8.9071e-01],\n",
      "        [-1.7145e-01,  2.2660e+00,  1.1257e+00, -2.0905e-01,  8.6608e-01,\n",
      "         -1.9981e+00,  2.6479e-01,  7.2438e-01],\n",
      "        [ 6.1478e-01, -6.6548e-01, -7.2467e-01,  1.4909e-01, -3.0492e-01,\n",
      "          1.9789e+00,  4.9170e-01,  5.9220e-01],\n",
      "        [-6.9467e-01, -1.8527e-01, -2.7025e-01,  5.3667e-01, -4.6911e-01,\n",
      "          3.9227e-01, -8.2414e-01, -1.4445e+00],\n",
      "        [-7.5266e-01, -2.1692e-01,  7.2461e-01, -2.0918e+00, -7.4598e-01,\n",
      "          7.2764e-01,  1.7699e-02, -8.9071e-01],\n",
      "        [ 1.5417e+00,  1.1712e+00, -6.5890e-01, -1.3323e+00, -4.1057e-01,\n",
      "         -1.5926e+00,  3.9475e-02, -3.5899e-01],\n",
      "        [ 8.1892e-01,  1.1678e-01, -7.4139e-01,  2.8687e-01, -2.2373e+00,\n",
      "          1.5243e+00, -1.1252e+00,  3.7009e-01],\n",
      "        [-1.2478e+00,  2.9411e-01,  3.4960e-01,  5.0402e-01,  1.3946e+00,\n",
      "          2.4824e-01,  7.4986e-01,  2.9281e-01],\n",
      "        [ 8.8312e-01,  3.3682e-01, -9.0718e-01, -2.2868e-01, -8.8114e-01,\n",
      "          1.7723e-02,  1.2431e+00, -1.6171e-01],\n",
      "        [ 7.3056e-02, -1.8421e+00,  4.1404e-01, -1.8534e-01, -3.8059e-01,\n",
      "          5.8416e-01, -2.6752e-01,  4.0789e-01],\n",
      "        [ 1.5417e+00,  1.1712e+00, -6.5890e-01, -1.3323e+00, -4.1057e-01,\n",
      "         -1.5926e+00,  3.9475e-02, -3.5899e-01],\n",
      "        [-1.3905e+00,  3.6324e-02, -1.1547e+00, -1.5011e+00, -1.1054e+00,\n",
      "         -5.0780e-01, -1.5228e-01, -1.7254e-01],\n",
      "        [ 1.4545e+00, -1.3275e+00,  2.1460e+00,  4.3348e-01, -7.6122e-01,\n",
      "          2.6432e-01,  1.9517e+00,  1.6368e-01],\n",
      "        [ 1.5417e+00,  1.1712e+00, -6.5890e-01, -1.3323e+00, -4.1057e-01,\n",
      "         -1.5926e+00,  3.9475e-02, -3.5899e-01],\n",
      "        [ 7.1323e-01,  1.7449e+00,  2.5276e-01, -4.0396e-01, -4.7683e-01,\n",
      "          4.2984e-01,  9.3957e-01,  1.8152e-01],\n",
      "        [ 3.4202e-02, -5.7507e-01, -2.7692e-01,  1.6847e+00,  1.1843e-02,\n",
      "          3.0646e-02, -3.7261e-01, -1.3673e+00],\n",
      "        [-1.8198e+00,  4.9082e-01, -1.0441e+00, -1.2077e+00, -4.2039e-01,\n",
      "          2.9279e-01, -2.9335e-01, -8.9023e-01],\n",
      "        [-1.2336e+00, -9.7117e-01, -1.1459e+00,  4.6709e-01,  1.1247e+00,\n",
      "          1.0526e+00,  7.0910e-01,  1.8778e+00],\n",
      "        [-1.6419e+00, -4.6088e-01,  1.7740e+00, -2.2663e-01, -9.2842e-01,\n",
      "          9.6005e-01,  4.2393e-01,  7.7496e-01],\n",
      "        [ 1.5417e+00,  1.1712e+00, -6.5890e-01, -1.3323e+00, -4.1057e-01,\n",
      "         -1.5926e+00,  3.9475e-02, -3.5899e-01],\n",
      "        [ 3.9222e-01,  3.1698e-01,  5.7620e-01,  2.8518e-01,  8.8265e-01,\n",
      "          2.3176e-01, -4.2792e-01, -4.3441e-03],\n",
      "        [-3.5619e-01, -1.1325e+00,  6.4733e-01,  1.7356e+00, -5.8374e-01,\n",
      "          1.6300e+00,  1.1204e+00,  2.4000e-02],\n",
      "        [-1.0247e+00,  6.6879e-01,  1.6406e+00,  5.1521e-01, -4.5884e-01,\n",
      "         -8.8270e-01,  2.1202e+00,  6.5250e-01],\n",
      "        [-3.5619e-01, -1.1325e+00,  6.4733e-01,  1.7356e+00, -5.8374e-01,\n",
      "          1.6300e+00,  1.1204e+00,  2.4000e-02],\n",
      "        [ 9.4815e-06, -1.3404e+00, -7.8816e-01,  2.1162e-01,  8.3150e-01,\n",
      "         -4.1949e-01,  2.7758e-01,  9.6349e-01],\n",
      "        [-1.4086e+00, -1.4212e+00, -1.0490e+00, -8.6374e-01, -1.7935e+00,\n",
      "          1.7698e+00,  1.0187e+00,  5.8245e-01],\n",
      "        [ 1.1150e+00,  1.3453e-01,  4.4128e-01,  2.9417e-01, -5.9749e-01,\n",
      "          9.0529e-02,  1.2433e-01, -4.5994e-01],\n",
      "        [-6.8763e-01, -1.6777e+00, -1.7813e+00, -1.3523e-01, -6.9792e-01,\n",
      "         -1.8846e+00,  1.5042e+00, -2.0089e+00],\n",
      "        [ 9.2422e-01,  1.5713e-01,  1.1718e-01,  6.4099e-01,  4.6515e-01,\n",
      "         -6.5121e-01, -1.0691e+00,  1.4528e+00],\n",
      "        [ 3.9222e-01,  3.1698e-01,  5.7620e-01,  2.8518e-01,  8.8265e-01,\n",
      "          2.3176e-01, -4.2792e-01, -4.3441e-03],\n",
      "        [ 1.4545e+00, -1.3275e+00,  2.1460e+00,  4.3348e-01, -7.6122e-01,\n",
      "          2.6432e-01,  1.9517e+00,  1.6368e-01],\n",
      "        [ 2.3122e+00,  8.7942e-01, -8.1184e-01, -7.4277e-01, -1.2574e+00,\n",
      "          5.2758e-02, -1.3929e-01,  7.7635e-02],\n",
      "        [-6.8763e-01, -1.6777e+00, -1.7813e+00, -1.3523e-01, -6.9792e-01,\n",
      "         -1.8846e+00,  1.5042e+00, -2.0089e+00],\n",
      "        [-6.4965e-01, -1.8758e+00, -5.7985e-02, -2.0377e+00, -5.6319e-01,\n",
      "         -7.2741e-01,  1.3506e+00, -2.1917e-01],\n",
      "        [ 1.0765e+00,  7.3600e-01,  3.8702e-01, -1.4115e+00,  1.0507e+00,\n",
      "         -2.0011e-02, -1.0867e+00,  1.2022e-02],\n",
      "        [-9.9267e-01, -1.3970e+00,  1.1439e-01,  5.3151e-01, -2.8849e-01,\n",
      "          4.0786e-01,  1.7249e+00,  7.4025e-01],\n",
      "        [ 5.7222e-01, -1.2307e+00, -2.0069e-01,  2.3877e-01, -8.3380e-01,\n",
      "         -7.3330e-01, -2.0244e+00,  2.9264e-01]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(caption_batch[0])\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial h shape = torch.Size([2, 16])\n",
      "Initial c shape = torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "h = decoder.init_h(feature_mean)\n",
    "c = decoder.init_c(feature_mean)\n",
    "\n",
    "print(f\"Initial h shape = {h.shape}\")\n",
    "print(f\"Initial c shape = {c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0481, -0.0754,  0.0214,  0.0341, -0.0656,  0.2027,  0.1674, -0.2163,\n",
      "         0.1609, -0.1088,  0.0044,  0.1104,  0.1710,  0.1353,  0.1631,  0.1088],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0339, -0.0613, -0.3734, -0.3021,  0.0724,  0.1590,  0.1821,  0.1939,\n",
      "         0.1842, -0.0871, -0.1829, -0.0557, -0.0951,  0.2427, -0.0032, -0.1451],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Initial h, c of LSTM computed by MLP(feature_maps_mean)\n",
    "print(h[0])\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5722, -1.2307, -0.2007,  0.2388, -0.8338, -0.7333, -2.0244,  0.2926],\n",
       "        [ 0.5722, -1.2307, -0.2007,  0.2388, -0.8338, -0.7333, -2.0244,  0.2926]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get word embeddings of words at particular index of a caption in batch\n",
    "index = 50\n",
    "embeddings[:, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1412, 0.1195, 0.1757, 0.1956, 0.2014, 0.1619, 0.1296, 0.1212, 0.1625,\n",
       "         0.2444, 0.2788, 0.3305, 0.3097, 0.3634, 0.2017, 0.1454, 0.0949, 0.0646,\n",
       "         0.0738, 0.0580, 0.0685, 0.0834, 0.1497, 0.3198, 0.2564, 0.2706, 0.2274,\n",
       "         0.2668, 0.4305, 0.2778, 0.3106, 0.2719, 0.2167, 0.0923, 0.0908, 0.1187,\n",
       "         0.3236, 0.6264, 0.3948, 0.4090, 0.3418, 0.3622, 0.3230, 0.1912, 0.2707,\n",
       "         0.2215, 0.1806, 0.0852, 0.0931, 0.1090, 0.2908, 0.4428, 0.1921, 0.2183,\n",
       "         0.2172, 0.3397, 0.3572, 0.2309, 0.2297, 0.1774, 0.2011, 0.1361, 0.1507,\n",
       "         0.1538, 0.2483, 0.2350, 0.1305, 0.1665, 0.2978, 0.4957, 0.3393, 0.1802,\n",
       "         0.1848, 0.1314, 0.2549, 0.3474, 0.3141, 0.2434, 0.2089, 0.1747, 0.2000,\n",
       "         0.2210, 0.3853, 0.5794, 0.2008, 0.1367, 0.1783, 0.1296, 0.2880, 0.4784,\n",
       "         0.5109, 0.4420, 0.3456, 0.3144, 0.3219, 0.3269, 0.3614, 0.5044, 0.2522,\n",
       "         0.1661, 0.2265, 0.1435, 0.2713, 0.4259, 0.4878, 0.4517, 0.3450, 0.2899,\n",
       "         0.2741, 0.2950, 0.3401, 0.4399, 0.2932, 0.2313, 0.3534, 0.2611, 0.3260,\n",
       "         0.3536, 0.4130, 0.4175, 0.3646, 0.3397, 0.3101, 0.3242, 0.3097, 0.3636,\n",
       "         0.2150, 0.1634, 0.3246, 0.2434, 0.2508, 0.2482, 0.2858, 0.2830, 0.2809,\n",
       "         0.2907, 0.2592, 0.2438, 0.2179, 0.2397, 0.1872, 0.1783, 0.3992, 0.3072,\n",
       "         0.2603, 0.2323, 0.2626, 0.2672, 0.2824, 0.2967, 0.3095, 0.3110, 0.2057,\n",
       "         0.1938, 0.1669, 0.1667, 0.3848, 0.2800, 0.2690, 0.2479, 0.2765, 0.2835,\n",
       "         0.2868, 0.3166, 0.3409, 0.3610, 0.2152, 0.1754, 0.0764, 0.0413, 0.1209,\n",
       "         0.0874, 0.1069, 0.1267, 0.1686, 0.1794, 0.1630, 0.1515, 0.1526, 0.1545,\n",
       "         0.0859, 0.0868, 0.1290, 0.0643, 0.1268, 0.1148, 0.1455, 0.1668, 0.2439,\n",
       "         0.2470, 0.1805, 0.1701, 0.1976, 0.2303, 0.1296, 0.1079],\n",
       "        [0.1741, 0.0801, 0.1035, 0.1055, 0.1187, 0.1308, 0.1595, 0.1957, 0.2268,\n",
       "         0.2774, 0.3237, 0.4506, 0.3448, 0.3125, 0.0962, 0.0501, 0.0558, 0.0482,\n",
       "         0.0534, 0.0530, 0.0617, 0.0883, 0.1416, 0.2479, 0.3094, 0.3759, 0.2664,\n",
       "         0.2388, 0.1373, 0.0582, 0.0966, 0.0773, 0.0841, 0.0906, 0.1046, 0.1501,\n",
       "         0.2111, 0.4186, 0.4966, 0.5952, 0.4593, 0.3463, 0.1030, 0.0424, 0.0969,\n",
       "         0.0788, 0.0898, 0.1254, 0.1398, 0.1278, 0.1440, 0.2580, 0.2966, 0.2902,\n",
       "         0.1905, 0.1361, 0.0979, 0.0600, 0.1240, 0.1083, 0.1269, 0.2019, 0.3088,\n",
       "         0.3049, 0.1863, 0.2683, 0.2083, 0.1237, 0.0847, 0.0728, 0.0773, 0.0530,\n",
       "         0.1156, 0.1271, 0.1494, 0.3874, 0.7495, 0.7648, 0.3806, 0.1225, 0.0825,\n",
       "         0.0438, 0.0417, 0.0376, 0.0593, 0.0435, 0.0837, 0.1135, 0.1880, 0.5625,\n",
       "         0.9928, 1.0152, 0.6882, 0.1317, 0.0747, 0.0426, 0.0415, 0.0372, 0.0493,\n",
       "         0.0446, 0.0686, 0.0931, 0.2053, 0.6412, 1.1315, 1.0449, 0.7445, 0.1543,\n",
       "         0.0766, 0.0458, 0.0475, 0.0528, 0.0557, 0.0435, 0.0518, 0.0532, 0.1462,\n",
       "         0.3874, 0.6900, 0.5534, 0.3410, 0.1292, 0.0867, 0.0532, 0.0529, 0.0566,\n",
       "         0.0703, 0.0475, 0.0470, 0.0439, 0.0763, 0.1198, 0.1719, 0.1570, 0.1285,\n",
       "         0.0853, 0.0671, 0.0506, 0.0449, 0.0547, 0.0812, 0.0529, 0.0678, 0.0692,\n",
       "         0.0886, 0.1089, 0.1234, 0.1141, 0.0827, 0.0474, 0.0320, 0.0274, 0.0303,\n",
       "         0.0440, 0.1107, 0.0799, 0.0865, 0.0746, 0.0729, 0.0720, 0.0695, 0.0527,\n",
       "         0.0390, 0.0287, 0.0257, 0.0288, 0.0360, 0.0513, 0.0923, 0.0715, 0.0578,\n",
       "         0.0460, 0.0540, 0.0519, 0.0455, 0.0382, 0.0397, 0.0411, 0.0357, 0.0304,\n",
       "         0.0302, 0.0390, 0.1178, 0.0957, 0.0812, 0.0725, 0.0906, 0.0962, 0.0868,\n",
       "         0.0813, 0.0801, 0.0818, 0.0671, 0.0638, 0.0685, 0.0946]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5722, -1.2307, -0.2007,  0.2388, -0.8338, -0.7333, -2.0244,  0.2926,\n",
       "          0.1412,  0.1195,  0.1757,  0.1956,  0.2014,  0.1619,  0.1296,  0.1212,\n",
       "          0.1625,  0.2444,  0.2788,  0.3305,  0.3097,  0.3634,  0.2017,  0.1454,\n",
       "          0.0949,  0.0646,  0.0738,  0.0580,  0.0685,  0.0834,  0.1497,  0.3198,\n",
       "          0.2564,  0.2706,  0.2274,  0.2668,  0.4305,  0.2778,  0.3106,  0.2719,\n",
       "          0.2167,  0.0923,  0.0908,  0.1187,  0.3236,  0.6264,  0.3948,  0.4090,\n",
       "          0.3418,  0.3622,  0.3230,  0.1912,  0.2707,  0.2215,  0.1806,  0.0852,\n",
       "          0.0931,  0.1090,  0.2908,  0.4428,  0.1921,  0.2183,  0.2172,  0.3397,\n",
       "          0.3572,  0.2309,  0.2297,  0.1774,  0.2011,  0.1361,  0.1507,  0.1538,\n",
       "          0.2483,  0.2350,  0.1305,  0.1665,  0.2978,  0.4957,  0.3393,  0.1802,\n",
       "          0.1848,  0.1314,  0.2549,  0.3474,  0.3141,  0.2434,  0.2089,  0.1747,\n",
       "          0.2000,  0.2210,  0.3853,  0.5794,  0.2008,  0.1367,  0.1783,  0.1296,\n",
       "          0.2880,  0.4784,  0.5109,  0.4420,  0.3456,  0.3144,  0.3219,  0.3269,\n",
       "          0.3614,  0.5044,  0.2522,  0.1661,  0.2265,  0.1435,  0.2713,  0.4259,\n",
       "          0.4878,  0.4517,  0.3450,  0.2899,  0.2741,  0.2950,  0.3401,  0.4399,\n",
       "          0.2932,  0.2313,  0.3534,  0.2611,  0.3260,  0.3536,  0.4130,  0.4175,\n",
       "          0.3646,  0.3397,  0.3101,  0.3242,  0.3097,  0.3636,  0.2150,  0.1634,\n",
       "          0.3246,  0.2434,  0.2508,  0.2482,  0.2858,  0.2830,  0.2809,  0.2907,\n",
       "          0.2592,  0.2438,  0.2179,  0.2397,  0.1872,  0.1783,  0.3992,  0.3072,\n",
       "          0.2603,  0.2323,  0.2626,  0.2672,  0.2824,  0.2967,  0.3095,  0.3110,\n",
       "          0.2057,  0.1938,  0.1669,  0.1667,  0.3848,  0.2800,  0.2690,  0.2479,\n",
       "          0.2765,  0.2835,  0.2868,  0.3166,  0.3409,  0.3610,  0.2152,  0.1754,\n",
       "          0.0764,  0.0413,  0.1209,  0.0874,  0.1069,  0.1267,  0.1686,  0.1794,\n",
       "          0.1630,  0.1515,  0.1526,  0.1545,  0.0859,  0.0868,  0.1290,  0.0643,\n",
       "          0.1268,  0.1148,  0.1455,  0.1668,  0.2439,  0.2470,  0.1805,  0.1701,\n",
       "          0.1976,  0.2303,  0.1296,  0.1079],\n",
       "        [ 0.5722, -1.2307, -0.2007,  0.2388, -0.8338, -0.7333, -2.0244,  0.2926,\n",
       "          0.1741,  0.0801,  0.1035,  0.1055,  0.1187,  0.1308,  0.1595,  0.1957,\n",
       "          0.2268,  0.2774,  0.3237,  0.4506,  0.3448,  0.3125,  0.0962,  0.0501,\n",
       "          0.0558,  0.0482,  0.0534,  0.0530,  0.0617,  0.0883,  0.1416,  0.2479,\n",
       "          0.3094,  0.3759,  0.2664,  0.2388,  0.1373,  0.0582,  0.0966,  0.0773,\n",
       "          0.0841,  0.0906,  0.1046,  0.1501,  0.2111,  0.4186,  0.4966,  0.5952,\n",
       "          0.4593,  0.3463,  0.1030,  0.0424,  0.0969,  0.0788,  0.0898,  0.1254,\n",
       "          0.1398,  0.1278,  0.1440,  0.2580,  0.2966,  0.2902,  0.1905,  0.1361,\n",
       "          0.0979,  0.0600,  0.1240,  0.1083,  0.1269,  0.2019,  0.3088,  0.3049,\n",
       "          0.1863,  0.2683,  0.2083,  0.1237,  0.0847,  0.0728,  0.0773,  0.0530,\n",
       "          0.1156,  0.1271,  0.1494,  0.3874,  0.7495,  0.7648,  0.3806,  0.1225,\n",
       "          0.0825,  0.0438,  0.0417,  0.0376,  0.0593,  0.0435,  0.0837,  0.1135,\n",
       "          0.1880,  0.5625,  0.9928,  1.0152,  0.6882,  0.1317,  0.0747,  0.0426,\n",
       "          0.0415,  0.0372,  0.0493,  0.0446,  0.0686,  0.0931,  0.2053,  0.6412,\n",
       "          1.1315,  1.0449,  0.7445,  0.1543,  0.0766,  0.0458,  0.0475,  0.0528,\n",
       "          0.0557,  0.0435,  0.0518,  0.0532,  0.1462,  0.3874,  0.6900,  0.5534,\n",
       "          0.3410,  0.1292,  0.0867,  0.0532,  0.0529,  0.0566,  0.0703,  0.0475,\n",
       "          0.0470,  0.0439,  0.0763,  0.1198,  0.1719,  0.1570,  0.1285,  0.0853,\n",
       "          0.0671,  0.0506,  0.0449,  0.0547,  0.0812,  0.0529,  0.0678,  0.0692,\n",
       "          0.0886,  0.1089,  0.1234,  0.1141,  0.0827,  0.0474,  0.0320,  0.0274,\n",
       "          0.0303,  0.0440,  0.1107,  0.0799,  0.0865,  0.0746,  0.0729,  0.0720,\n",
       "          0.0695,  0.0527,  0.0390,  0.0287,  0.0257,  0.0288,  0.0360,  0.0513,\n",
       "          0.0923,  0.0715,  0.0578,  0.0460,  0.0540,  0.0519,  0.0455,  0.0382,\n",
       "          0.0397,  0.0411,  0.0357,  0.0304,  0.0302,  0.0390,  0.1178,  0.0957,\n",
       "          0.0812,  0.0725,  0.0906,  0.0962,  0.0868,  0.0813,  0.0801,  0.0818,\n",
       "          0.0671,  0.0638,  0.0685,  0.0946]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to concatenate context and embedding word\n",
    "torch.cat([embeddings[:, index], feature_mean], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-95cd923a27bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_maps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#predictions, contexts = decoder.forward(feature_maps, feature_mean, caption_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 51])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of predicted words == caption_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / 10_000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random guess prediction probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_t, hidden, context = decoder.forward(feature_maps, feature_mean, caption_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1818, -0.1165,  0.0341, -0.0915,  0.0902, -0.1428,  0.0529,  0.1196],\n",
       "        [-0.0950,  0.0188, -0.0773, -0.0995, -0.0248, -0.1069,  0.1902,  0.2213]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0579, -0.1055, -0.0308,  0.0559, -0.2519,  0.0609,  0.2156, -0.0496],\n",
       "        [ 0.0955, -0.0668, -0.2021,  0.0172, -0.1793,  0.0961,  0.1042, -0.1226]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3225, -0.4640,  1.1217, -1.9029, -0.4754, -3.0222, -0.0267,  0.1619],\n",
       "        [-2.3225, -0.4640,  1.1217, -1.9029, -0.4754, -3.0222, -0.0267,  0.1619]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5622, -0.6861,  1.1251, -1.9385, -0.6371, -3.1042,  0.2417,  0.2318],\n",
       "        [-2.3220, -0.5121,  0.8423, -1.9852, -0.6795, -3.0330,  0.2677,  0.2606]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_t + hidden + context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, contexts = decoder.forward(feature_maps, feature_mean, caption_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 2, 10004])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 2, 196])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
